{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9LpY5+/fIwQKYr7PpjLK4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmestanza/natural-language-processing-practice/blob/main/desafios/Desafio_2/Desafio_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crear sus propios vectores con Gensim\n",
        "basado en lo visto en clase con otro\n",
        "dataset.\n",
        "Probar términos de interés y explicar\n",
        "similitudes en el espacio de embeddings.\n",
        "Intentar plantear y probar tests de\n",
        "analogías. Graficar los embeddings\n",
        "resultantes.\n",
        "Sacar conclusiones."
      ],
      "metadata": {
        "id": "ItlvXdgo_tqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algunos de los sitios de textos sugeridos fueron:\n",
        "- [Project Gutenberg](https://www.gutenberg.org/browse/scores/top)\n",
        "- [Textos.info](https://www.textos.info/)\n",
        "\n",
        "Se eligió analizar los textos pertenecientes a [The Project Gutenberg eBook of The Adventures of Sherlock Holmes](https://www.gutenberg.org/cache/epub/1661/pg1661.txt)\n"
      ],
      "metadata": {
        "id": "pFC94kllBtua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por razones de compatibilidad con gensim, pandas y numpy hay que correr la siguiente linea de código."
      ],
      "metadata": {
        "id": "XPzpE--p1_0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy gensim\n",
        "!pip install --upgrade numpy gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aPNpbiO1uNG",
        "outputId": "66a6bcaa-b5e4-4e3e-ccc7-06a53661bd77"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Found existing installation: gensim 4.3.3\n",
            "Uninstalling gensim-4.3.3:\n",
            "  Successfully uninstalled gensim-4.3.3\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy, gensim\n",
            "Successfully installed gensim-4.3.3 numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "filename = 'dataset.txt'\n",
        "text_path = 'https://raw.githubusercontent.com/jmestanza/natural-language-processing-practice/refs/heads/main/desafios/Desafio_2/the_adventures_of_sherlock_holmes.txt'\n",
        "curr_dir = os.getcwd()\n",
        "dataset_path = os.path.join(curr_dir, filename)\n",
        "if not os.path.exists(dataset_path):\n",
        "  !wget {text_path} -O {filename}\n",
        "\n",
        "os.listdir(curr_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgdNH4GdFvk7",
        "outputId": "ff03fa9d-47d6-4635-8cd9-0c7e1e240435"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'dataset_clean.txt', 'dataset.txt', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(dataset_path, 'r') as f:\n",
        "  text = f.read()\n",
        "\n",
        "print(text[:1500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-2-XwJ7G7Eq",
        "outputId": "8d993de1-21f3-458e-af3c-6aa62c2985fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of The Adventures of Sherlock Holmes\n",
            "    \n",
            "This ebook is for the use of anyone anywhere in the United States and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\n",
            "of the Project Gutenberg License included with this ebook or online\n",
            "at www.gutenberg.org. If you are not located in the United States,\n",
            "you will have to check the laws of the country where you are located\n",
            "before using this eBook.\n",
            "\n",
            "Title: The Adventures of Sherlock Holmes\n",
            "\n",
            "Author: Arthur Conan Doyle\n",
            "\n",
            "Release date: March 1, 1999 [eBook #1661]\n",
            "                Most recently updated: October 10, 2023\n",
            "\n",
            "Language: English\n",
            "\n",
            "Credits: an anonymous Project Gutenberg volunteer and Jose Menendez\n",
            "\n",
            "\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK THE ADVENTURES OF SHERLOCK HOLMES ***\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The Adventures of Sherlock Holmes\n",
            "\n",
            "by Arthur Conan Doyle\n",
            "\n",
            "\n",
            "Contents\n",
            "\n",
            "   I.     A Scandal in Bohemia\n",
            "   II.    The Red-Headed League\n",
            "   III.   A Case of Identity\n",
            "   IV.    The Boscombe Valley Mystery\n",
            "   V.     The Five Orange Pips\n",
            "   VI.    The Man with the Twisted Lip\n",
            "   VII.   The Adventure of the Blue Carbuncle\n",
            "   VIII.  The Adventure of the Speckled Band\n",
            "   IX.    The Adventure of the Engineer’s Thumb\n",
            "   X.     The Adventure of the Noble Bachelor\n",
            "   XI.    The Adventure of the Beryl Coronet\n",
            "   XII.   The Adventure of the Copper Beeches\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "I. A SCANDAL IN BOHEMIA\n",
            "\n",
            "\n",
            "I.\n",
            "\n",
            "To Sherlock Holmes she is always _the_ woman. I have seldom heard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limpieza de dataset\n",
        "Debemos obtener solo los textos de adentro de los capítulos y subcapítulos.\n",
        "\n",
        "Además debemos ignorar el texto que viene con la metadata de la obra (presente en el principio y final del dataset).\n",
        "\n",
        "La estructura es\n",
        "\n",
        "\n",
        "```\n",
        "I. Chapter title\n",
        "I.\n",
        "text\n",
        "II.\n",
        "text\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "DHNPvr52LHLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Read the text file\n",
        "with open(dataset_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Remove everything before the actual content\n",
        "start_marker = \"*** START OF THE PROJECT GUTENBERG EBOOK\"\n",
        "end_marker = \"*** END OF THE PROJECT GUTENBERG EBOOK\"\n",
        "\n",
        "# Keep only the content between the start and end markers\n",
        "text = text.split(start_marker, 1)[-1].split(end_marker, 1)[0]\n",
        "\n",
        "# Define a pattern to match chapter titles (Roman numerals followed by title)\n",
        "chapter_pattern = re.compile(r\"\\n([IVXLCDM]+)\\.\\s([^\\n]+)\\n\")\n",
        "\n",
        "# Find all matches (chapter titles)\n",
        "matches = list(chapter_pattern.finditer(text))\n",
        "\n",
        "# Split the text into chapters\n",
        "chapters = []\n",
        "start = matches[0].end() if matches else 0  # Start at first chapter if found\n",
        "\n",
        "for i in range(len(matches)):\n",
        "    end = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
        "\n",
        "    chapter_title = matches[i].group(2)  # Extract chapter title (ignore Roman numeral)\n",
        "    chapter_content = text[matches[i].end():end].strip()\n",
        "\n",
        "    # Remove subchapter numbers (standalone Roman numerals followed by a newline)\n",
        "    chapter_content = re.sub(r\"^\\n?[IVXLCDM]+\\.\\n+\", \"\", chapter_content, flags=re.MULTILINE).strip()\n",
        "\n",
        "    # Store as \"Chapter Title\\nContent\"\n",
        "    chapters.append(f\"{chapter_title}\\n\\n{chapter_content}\")\n",
        "\n",
        "# Print the first 300 characters of each chapter\n",
        "for i, chapter in enumerate(chapters, 1):\n",
        "    print(f\"Chapter {i}: {chapter[:300]}...\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAjFbkw3LEHI",
        "outputId": "b60228f1-a3a2-4e98-f371-974cd1eb5c7a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chapter 1: A SCANDAL IN BOHEMIA\n",
            "\n",
            "To Sherlock Holmes she is always _the_ woman. I have seldom heard him\n",
            "mention her under any other name. In his eyes she eclipses and\n",
            "predominates the whole of her sex. It was not that he felt any emotion\n",
            "akin to love for Irene Adler. All emotions, and that one particularly,\n",
            "wer...\n",
            "\n",
            "Chapter 2: THE RED-HEADED LEAGUE\n",
            "\n",
            "I had called upon my friend, Mr. Sherlock Holmes, one day in the\n",
            " autumn of last year and found him in deep conversation with a very\n",
            " stout, florid-faced, elderly gentleman with fiery red hair. With an\n",
            " apology for my intrusion, I was about to withdraw when Holmes pulled\n",
            " me a...\n",
            "\n",
            "Chapter 3: A CASE OF IDENTITY\n",
            "\n",
            "“My dear fellow,” said Sherlock Holmes as we sat on either side of the\n",
            "fire in his lodgings at Baker Street, “life is infinitely stranger than\n",
            "anything which the mind of man could invent. We would not dare to\n",
            "conceive the things which are really mere commonplaces of existence. If...\n",
            "\n",
            "Chapter 4: THE BOSCOMBE VALLEY MYSTERY\n",
            "\n",
            "We were seated at breakfast one morning, my wife and I, when the maid\n",
            "brought in a telegram. It was from Sherlock Holmes and ran in this way:\n",
            "\n",
            "“Have you a couple of days to spare? Have just been wired for from the\n",
            "west of England in connection with Boscombe Valley traged...\n",
            "\n",
            "Chapter 5: THE FIVE ORANGE PIPS\n",
            "\n",
            "When I glance over my notes and records of the Sherlock Holmes cases\n",
            "between the years ’82 and ’90, I am faced by so many which present\n",
            "strange and interesting features that it is no easy matter to know\n",
            "which to choose and which to leave. Some, however, have already gained\n",
            "publ...\n",
            "\n",
            "Chapter 6: THE MAN WITH THE TWISTED LIP\n",
            "\n",
            "Isa Whitney, brother of the late Elias Whitney, D.D., Principal of the\n",
            "Theological College of St. George’s, was much addicted to opium. The\n",
            "habit grew upon him, as I understand, from some foolish freak when he\n",
            "was at college; for having read De Quincey’s description of ...\n",
            "\n",
            "Chapter 7: THE ADVENTURE OF THE BLUE CARBUNCLE\n",
            "\n",
            "I had called upon my friend Sherlock Holmes upon the second morning\n",
            "after Christmas, with the intention of wishing him the compliments of\n",
            "the season. He was lounging upon the sofa in a purple dressing-gown, a\n",
            "pipe-rack within his reach upon the right, and a pile ...\n",
            "\n",
            "Chapter 8: THE ADVENTURE OF THE SPECKLED BAND\n",
            "\n",
            "On glancing over my notes of the seventy odd cases in which I have\n",
            "during the last eight years studied the methods of my friend Sherlock\n",
            "Holmes, I find many tragic, some comic, a large number merely strange,\n",
            "but none commonplace; for, working as he did rather for ...\n",
            "\n",
            "Chapter 9: THE ADVENTURE OF THE ENGINEER’S THUMB\n",
            "\n",
            "Of all the problems which have been submitted to my friend, Mr.\n",
            "Sherlock Holmes, for solution during the years of our intimacy, there\n",
            "were only two which I was the means of introducing to his notice—that\n",
            "of Mr. Hatherley’s thumb, and that of Colonel Warburton’s...\n",
            "\n",
            "Chapter 10: THE ADVENTURE OF THE NOBLE BACHELOR\n",
            "\n",
            "The Lord St. Simon marriage, and its curious termination, have long\n",
            "ceased to be a subject of interest in those exalted circles in which\n",
            "the unfortunate bridegroom moves. Fresh scandals have eclipsed it, and\n",
            "their more piquant details have drawn the gossips away ...\n",
            "\n",
            "Chapter 11: THE ADVENTURE OF THE BERYL CORONET\n",
            "\n",
            "“Holmes,” said I as I stood one morning in our bow-window looking down\n",
            "the street, “here is a madman coming along. It seems rather sad that\n",
            "his relatives should allow him to come out alone.”\n",
            "\n",
            "My friend rose lazily from his armchair and stood with his hands in the\n",
            "...\n",
            "\n",
            "Chapter 12: THE ADVENTURE OF THE COPPER BEECHES\n",
            "\n",
            "“To the man who loves art for its own sake,” remarked Sherlock Holmes,\n",
            "tossing aside the advertisement sheet of _The Daily Telegraph_, “it is\n",
            "frequently in its least important and lowliest manifestations that the\n",
            "keenest pleasure is to be derived. It is pleasant ...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = '\\n'.join(chapters)\n",
        "print(new_text[:1500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyvHFxpkNinv",
        "outputId": "5784a488-a8b5-4ea1-f0a9-c2c44780b552"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A SCANDAL IN BOHEMIA\n",
            "\n",
            "To Sherlock Holmes she is always _the_ woman. I have seldom heard him\n",
            "mention her under any other name. In his eyes she eclipses and\n",
            "predominates the whole of her sex. It was not that he felt any emotion\n",
            "akin to love for Irene Adler. All emotions, and that one particularly,\n",
            "were abhorrent to his cold, precise but admirably balanced mind. He\n",
            "was, I take it, the most perfect reasoning and observing machine that\n",
            "the world has seen, but as a lover he would have placed himself in a\n",
            "false position. He never spoke of the softer passions, save with a gibe\n",
            "and a sneer. They were admirable things for the observer—excellent for\n",
            "drawing the veil from men’s motives and actions. But for the trained\n",
            "reasoner to admit such intrusions into his own delicate and finely\n",
            "adjusted temperament was to introduce a distracting factor which might\n",
            "throw a doubt upon all his mental results. Grit in a sensitive\n",
            "instrument, or a crack in one of his own high-power lenses, would not\n",
            "be more disturbing than a strong emotion in a nature such as his. And\n",
            "yet there was but one woman to him, and that woman was the late Irene\n",
            "Adler, of dubious and questionable memory.\n",
            "\n",
            "I had seen little of Holmes lately. My marriage had drifted us away\n",
            "from each other. My own complete happiness, and the home-centred\n",
            "interests which rise up around the man who first finds himself master\n",
            "of his own establishment, were sufficient to absorb all my attention,\n",
            "while Holmes, who loathed every form of society with his\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('dataset_clean.txt', 'w') as f:\n",
        "  f.write(new_text)"
      ],
      "metadata": {
        "id": "t6-4w9RRbBxT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observando el dataset limpio, vemos que\n",
        "- `\\n\\n` (consecutive endline)\n",
        "- `_the_` (emphasis)\n",
        "- `“Seven!”` (punctuation)\n",
        "- `“Absolutely?”` (punctuation)\n",
        "- `John’s` (punctuation)\n",
        "- `won’t` (contractions)\n",
        "- `half-dragged` (hyphened compound-words)\n",
        "- `“‘The Church of St. Monica,` (abbreviation)\n",
        "- `\\t\\t“MY DEAR MR. SHERLOCK HOLMES` (tabs/spaces)\n",
        "- `_née_` (tilde)\n",
        "- `“‘Never.’` (quotes)\n",
        "- `“THE RED-HEADED LEAGUE IS DISSOLVED. October 9, 1890.”` (numbered date)\n",
        "- `sitting-room`\n",
        "- `“‘December 22nd. Twenty-four geese at 7_s_. 6_d_.’”`\n",
        "\n",
        "Deberíamos aplicar un preprocesamiento al texto.\n",
        "\n",
        "Una práctica recomendada es pasar todo a minúscula"
      ],
      "metadata": {
        "id": "omgwSL9NbH8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions dateparser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tbhrexq07bZA",
        "outputId": "be4f4540-edb1-4900-a749-502c4924ad58"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting dateparser\n",
            "  Downloading dateparser-1.2.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2025.1)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,>=2015.06.24 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (5.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->dateparser) (1.17.0)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading dateparser-1.2.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, dateparser, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 dateparser-1.2.1 pyahocorasick-2.1.0 textsearch-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import contractions\n",
        "import dateparser\n",
        "\n",
        "def preprocess_sherlock(text):\n",
        "    # 1. Normalize Line Breaks & Whitespace\n",
        "    text = re.sub(r'\\n+', '\\n', text)  # Reduce multiple newlines to one\n",
        "    text = re.sub(r'\\s+', ' ', text)   # Replace multiple spaces/tabs with a single space\n",
        "\n",
        "    # 2. Remove Emphasis (_the_ → the)\n",
        "    text = re.sub(r'_([^_]+)_', r'\\1', text)\n",
        "\n",
        "    # 3. Standardize Quotes & Punctuation\n",
        "    text = text.replace(\"“\", '\"').replace(\"”\", '\"').replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
        "\n",
        "    # 4. Expand Contractions (won’t → will not)\n",
        "    text = contractions.fix(text)\n",
        "\n",
        "    # 5. Normalize Hyphenated Words (half-dragged → half_dragged)\n",
        "    text = re.sub(r'(\\w+)-(\\w+)', r'\\1_\\2', text)\n",
        "\n",
        "    # 6. Normalize Abbreviations (St. → Saint)\n",
        "    abbreviations = {\"St.\": \"Saint\", \"Dr.\": \"Doctor\"}\n",
        "    for abbr, full in abbreviations.items():\n",
        "        text = re.sub(r'\\b' + re.escape(abbr) + r'\\b', full, text)\n",
        "\n",
        "    # 7. Convert Numbered Dates (October 9, 1890 → 1890-10-09)\n",
        "    text = re.sub(r'(\\b[A-Za-z]+ \\d{1,2}, \\d{4})',\n",
        "                  lambda m: dateparser.parse(m.group(0)).strftime('%Y-%m-%d'), text)\n",
        "\n",
        "    # 8. Normalize Money & Measurements (7_s_. 6_d_. → 7s 6d)\n",
        "    text = re.sub(r'(\\d+)_s_\\.? (\\d+)_d_\\.?', r'\\1s \\2d', text)\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "EbjyQ2MR7YL0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('dataset_clean_preprocessed.txt', 'w') as f:\n",
        "  f.write(preprocess_sherlock(new_text))"
      ],
      "metadata": {
        "id": "H6We-eJZ7i-U"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Preprocesamiento"
      ],
      "metadata": {
        "id": "cjlZz6kqZexn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('dataset_clean_preprocessed.txt', sep='/n', header=None)\n",
        "# df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOA_1YbMpjLo",
        "outputId": "3ec33fbb-a9af-4890-f74b-a40c137ea695"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-12cfb9028a78>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  df = pd.read_csv('dataset_clean_preprocessed.txt', sep='/n', header=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cantidad de lineas:\", df.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szc70eRtp-Wr",
        "outputId": "876de7dc-eeb5-4754-a9c7-471e665cc67f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de lineas: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "sentence_tokens = []\n",
        "# Recorrer todas las filas y transformar las oraciones\n",
        "# en una secuencia de palabras (esto podría realizarse con NLTK o spaCy también)\n",
        "for _, row in df[:None].iterrows():\n",
        "    sentence_tokens.append(text_to_word_sequence(row[0]))\n",
        "\n"
      ],
      "metadata": {
        "id": "d0j6ndLma8pv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0f5W3K-qExF",
        "outputId": "1088e44d-f700-4faa-ee58-5737c9fac43a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['a',\n",
              "  'scandal',\n",
              "  'in',\n",
              "  'bohemia',\n",
              "  'to',\n",
              "  'sherlock',\n",
              "  'holmes',\n",
              "  'she',\n",
              "  'is',\n",
              "  'always',\n",
              "  'the',\n",
              "  'woman',\n",
              "  'i',\n",
              "  'have',\n",
              "  'seldom',\n",
              "  'heard',\n",
              "  'him',\n",
              "  'mention',\n",
              "  'her',\n",
              "  'under',\n",
              "  'any',\n",
              "  'other',\n",
              "  'name',\n",
              "  'in',\n",
              "  'his',\n",
              "  'eyes',\n",
              "  'she',\n",
              "  'eclipses',\n",
              "  'and',\n",
              "  'predominates',\n",
              "  'the',\n",
              "  'whole',\n",
              "  'of',\n",
              "  'her',\n",
              "  'sex',\n",
              "  'it',\n",
              "  'was',\n",
              "  'not',\n",
              "  'that',\n",
              "  'he',\n",
              "  'felt',\n",
              "  'any',\n",
              "  'emotion',\n",
              "  'akin',\n",
              "  'to',\n",
              "  'love',\n",
              "  'for',\n",
              "  'irene',\n",
              "  'adler',\n",
              "  'all',\n",
              "  'emotions',\n",
              "  'and',\n",
              "  'that',\n",
              "  'one',\n",
              "  'particularly',\n",
              "  'were',\n",
              "  'abhorrent',\n",
              "  'to',\n",
              "  'his',\n",
              "  'cold',\n",
              "  'precise',\n",
              "  'but',\n",
              "  'admirably',\n",
              "  'balanced',\n",
              "  'mind',\n",
              "  'he',\n",
              "  'was',\n",
              "  'i',\n",
              "  'take',\n",
              "  'it',\n",
              "  'the',\n",
              "  'most',\n",
              "  'perfect',\n",
              "  'reasoning',\n",
              "  'and',\n",
              "  'observing',\n",
              "  'machine',\n",
              "  'that',\n",
              "  'the',\n",
              "  'world',\n",
              "  'has',\n",
              "  'seen',\n",
              "  'but',\n",
              "  'as',\n",
              "  'a',\n",
              "  'lover',\n",
              "  'he',\n",
              "  'would',\n",
              "  'have',\n",
              "  'placed',\n",
              "  'himself',\n",
              "  'in',\n",
              "  'a',\n",
              "  'false',\n",
              "  'position',\n",
              "  'he',\n",
              "  'never',\n",
              "  'spoke',\n",
              "  'of',\n",
              "  'the',\n",
              "  'softer',\n",
              "  'passions',\n",
              "  'save',\n",
              "  'with',\n",
              "  'a',\n",
              "  'gibe',\n",
              "  'and',\n",
              "  'a',\n",
              "  'sneer',\n",
              "  'they',\n",
              "  'were',\n",
              "  'admirable',\n",
              "  'things',\n",
              "  'for',\n",
              "  'the',\n",
              "  'observer—excellent',\n",
              "  'for',\n",
              "  'drawing',\n",
              "  'the',\n",
              "  'veil',\n",
              "  'from',\n",
              "  \"men's\",\n",
              "  'motives',\n",
              "  'and',\n",
              "  'actions',\n",
              "  'but',\n",
              "  'for',\n",
              "  'the',\n",
              "  'trained',\n",
              "  'reasoner',\n",
              "  'to',\n",
              "  'admit',\n",
              "  'such',\n",
              "  'intrusions',\n",
              "  'into',\n",
              "  'his',\n",
              "  'own',\n",
              "  'delicate',\n",
              "  'and',\n",
              "  'finely',\n",
              "  'adjusted',\n",
              "  'temperament',\n",
              "  'was',\n",
              "  'to',\n",
              "  'introduce',\n",
              "  'a',\n",
              "  'distracting',\n",
              "  'factor',\n",
              "  'which',\n",
              "  'might',\n",
              "  'throw',\n",
              "  'a',\n",
              "  'doubt',\n",
              "  'upon',\n",
              "  'all',\n",
              "  'his',\n",
              "  'mental',\n",
              "  'results',\n",
              "  'grit',\n",
              "  'in',\n",
              "  'a',\n",
              "  'sensitive',\n",
              "  'instrument',\n",
              "  'or',\n",
              "  'a',\n",
              "  'crack',\n",
              "  'in',\n",
              "  'one',\n",
              "  'of',\n",
              "  'his',\n",
              "  'own',\n",
              "  'high',\n",
              "  'power',\n",
              "  'lenses',\n",
              "  'would',\n",
              "  'not',\n",
              "  'be',\n",
              "  'more',\n",
              "  'disturbing',\n",
              "  'than',\n",
              "  'a',\n",
              "  'strong',\n",
              "  'emotion',\n",
              "  'in',\n",
              "  'a',\n",
              "  'nature',\n",
              "  'such',\n",
              "  'as',\n",
              "  'his',\n",
              "  'and',\n",
              "  'yet',\n",
              "  'there',\n",
              "  'was',\n",
              "  'but',\n",
              "  'one',\n",
              "  'woman',\n",
              "  'to',\n",
              "  'him',\n",
              "  'and',\n",
              "  'that',\n",
              "  'woman',\n",
              "  'was',\n",
              "  'the',\n",
              "  'late',\n",
              "  'irene',\n",
              "  'adler',\n",
              "  'of',\n",
              "  'dubious',\n",
              "  'and',\n",
              "  'questionable',\n",
              "  'memory',\n",
              "  'i',\n",
              "  'had',\n",
              "  'seen',\n",
              "  'little',\n",
              "  'of',\n",
              "  'holmes',\n",
              "  'lately',\n",
              "  'my',\n",
              "  'marriage',\n",
              "  'had',\n",
              "  'drifted',\n",
              "  'us',\n",
              "  'away',\n",
              "  'from',\n",
              "  'each',\n",
              "  'other',\n",
              "  'my',\n",
              "  'own',\n",
              "  'complete',\n",
              "  'happiness',\n",
              "  'and',\n",
              "  'the',\n",
              "  'home',\n",
              "  'centred',\n",
              "  'interests',\n",
              "  'which',\n",
              "  'rise',\n",
              "  'up',\n",
              "  'around',\n",
              "  'the',\n",
              "  'man',\n",
              "  'who',\n",
              "  'first',\n",
              "  'finds',\n",
              "  'himself',\n",
              "  'master',\n",
              "  'of',\n",
              "  'his',\n",
              "  'own',\n",
              "  'establishment',\n",
              "  'were',\n",
              "  'sufficient',\n",
              "  'to',\n",
              "  'absorb',\n",
              "  'all',\n",
              "  'my',\n",
              "  'attention',\n",
              "  'while',\n",
              "  'holmes',\n",
              "  'who',\n",
              "  'loathed',\n",
              "  'every',\n",
              "  'form',\n",
              "  'of',\n",
              "  'society',\n",
              "  'with',\n",
              "  'his',\n",
              "  'whole',\n",
              "  'bohemian',\n",
              "  'soul',\n",
              "  'remained',\n",
              "  'in',\n",
              "  'our',\n",
              "  'lodgings',\n",
              "  'in',\n",
              "  'baker',\n",
              "  'street',\n",
              "  'buried',\n",
              "  'among',\n",
              "  'his',\n",
              "  'old',\n",
              "  'books',\n",
              "  'and',\n",
              "  'alternating',\n",
              "  'from',\n",
              "  'week',\n",
              "  'to',\n",
              "  'week',\n",
              "  'between',\n",
              "  'cocaine',\n",
              "  'and',\n",
              "  'ambition',\n",
              "  'the',\n",
              "  'drowsiness',\n",
              "  'of',\n",
              "  'the',\n",
              "  'drug',\n",
              "  'and',\n",
              "  'the',\n",
              "  'fierce',\n",
              "  'energy',\n",
              "  'of',\n",
              "  'his',\n",
              "  'own',\n",
              "  'keen',\n",
              "  'nature',\n",
              "  'he',\n",
              "  'was',\n",
              "  'still',\n",
              "  'as',\n",
              "  'ever',\n",
              "  'deeply',\n",
              "  'attracted',\n",
              "  'by',\n",
              "  'the',\n",
              "  'study',\n",
              "  'of',\n",
              "  'crime',\n",
              "  'and',\n",
              "  'occupied',\n",
              "  'his',\n",
              "  'immense',\n",
              "  'faculties',\n",
              "  'and',\n",
              "  'extraordinary',\n",
              "  'powers',\n",
              "  'of',\n",
              "  'observation',\n",
              "  'in',\n",
              "  'following',\n",
              "  'out',\n",
              "  'those',\n",
              "  'clues',\n",
              "  'and',\n",
              "  'clearing',\n",
              "  'up',\n",
              "  'those',\n",
              "  'mysteries',\n",
              "  'which',\n",
              "  'had',\n",
              "  'been',\n",
              "  'abandoned',\n",
              "  'as',\n",
              "  'hopeless',\n",
              "  'by',\n",
              "  'the',\n",
              "  'official',\n",
              "  'police',\n",
              "  'from',\n",
              "  'time',\n",
              "  'to',\n",
              "  'time',\n",
              "  'i',\n",
              "  'heard',\n",
              "  'some',\n",
              "  'vague',\n",
              "  'account',\n",
              "  'of',\n",
              "  'his',\n",
              "  'doings',\n",
              "  'of',\n",
              "  'his',\n",
              "  'summons',\n",
              "  'to',\n",
              "  'odessa',\n",
              "  'in',\n",
              "  'the',\n",
              "  'case',\n",
              "  'of',\n",
              "  'the',\n",
              "  'trepoff',\n",
              "  'murder',\n",
              "  'of',\n",
              "  'his',\n",
              "  'clearing',\n",
              "  'up',\n",
              "  'of',\n",
              "  'the',\n",
              "  'singular',\n",
              "  'tragedy',\n",
              "  'of',\n",
              "  'the',\n",
              "  'atkinson',\n",
              "  'brothers',\n",
              "  'at',\n",
              "  'trincomalee',\n",
              "  'and',\n",
              "  'finally',\n",
              "  'of',\n",
              "  'the',\n",
              "  'mission',\n",
              "  'which',\n",
              "  'he',\n",
              "  'had',\n",
              "  'accomplished',\n",
              "  'so',\n",
              "  'delicately',\n",
              "  'and',\n",
              "  'successfully',\n",
              "  'for',\n",
              "  'the',\n",
              "  'reigning',\n",
              "  'family',\n",
              "  'of',\n",
              "  'holland',\n",
              "  'beyond',\n",
              "  'these',\n",
              "  'signs',\n",
              "  'of',\n",
              "  'his',\n",
              "  'activity',\n",
              "  'however',\n",
              "  'which',\n",
              "  'i',\n",
              "  'merely',\n",
              "  'shared',\n",
              "  'with',\n",
              "  'all',\n",
              "  'the',\n",
              "  'readers',\n",
              "  'of',\n",
              "  'the',\n",
              "  'daily',\n",
              "  'press',\n",
              "  'i',\n",
              "  'knew',\n",
              "  'little',\n",
              "  'of',\n",
              "  'my',\n",
              "  'former',\n",
              "  'friend',\n",
              "  'and',\n",
              "  'companion',\n",
              "  'one',\n",
              "  'night—it',\n",
              "  'was',\n",
              "  'on',\n",
              "  'the',\n",
              "  'twentieth',\n",
              "  'of',\n",
              "  'march',\n",
              "  '1888—i',\n",
              "  'was',\n",
              "  'returning',\n",
              "  'from',\n",
              "  'a',\n",
              "  'journey',\n",
              "  'to',\n",
              "  'a',\n",
              "  'patient',\n",
              "  'for',\n",
              "  'i',\n",
              "  'had',\n",
              "  'now',\n",
              "  'returned',\n",
              "  'to',\n",
              "  'civil',\n",
              "  'practice',\n",
              "  'when',\n",
              "  'my',\n",
              "  'way',\n",
              "  'led',\n",
              "  'me',\n",
              "  'through',\n",
              "  'baker',\n",
              "  'street',\n",
              "  'as',\n",
              "  'i',\n",
              "  'passed',\n",
              "  'the',\n",
              "  'well',\n",
              "  'remembered',\n",
              "  'door',\n",
              "  'which',\n",
              "  'must',\n",
              "  'always',\n",
              "  'be',\n",
              "  'associated',\n",
              "  'in',\n",
              "  'my',\n",
              "  'mind',\n",
              "  'with',\n",
              "  'my',\n",
              "  'wooing',\n",
              "  'and',\n",
              "  'with',\n",
              "  'the',\n",
              "  'dark',\n",
              "  'incidents',\n",
              "  'of',\n",
              "  'the',\n",
              "  'study',\n",
              "  'in',\n",
              "  'scarlet',\n",
              "  'i',\n",
              "  'was',\n",
              "  'seized',\n",
              "  'with',\n",
              "  'a',\n",
              "  'keen',\n",
              "  'desire',\n",
              "  'to',\n",
              "  'see',\n",
              "  'holmes',\n",
              "  'again',\n",
              "  'and',\n",
              "  'to',\n",
              "  'know',\n",
              "  'how',\n",
              "  'he',\n",
              "  'was',\n",
              "  'employing',\n",
              "  'his',\n",
              "  'extraordinary',\n",
              "  'powers',\n",
              "  'his',\n",
              "  'rooms',\n",
              "  'were',\n",
              "  'brilliantly',\n",
              "  'lit',\n",
              "  'and',\n",
              "  'even',\n",
              "  'as',\n",
              "  'i',\n",
              "  'looked',\n",
              "  'up',\n",
              "  'i',\n",
              "  'saw',\n",
              "  'his',\n",
              "  'tall',\n",
              "  'spare',\n",
              "  'figure',\n",
              "  'pass',\n",
              "  'twice',\n",
              "  'in',\n",
              "  'a',\n",
              "  'dark',\n",
              "  'silhouette',\n",
              "  'against',\n",
              "  'the',\n",
              "  'blind',\n",
              "  'he',\n",
              "  'was',\n",
              "  'pacing',\n",
              "  'the',\n",
              "  'room',\n",
              "  'swiftly',\n",
              "  'eagerly',\n",
              "  'with',\n",
              "  'his',\n",
              "  'head',\n",
              "  'sunk',\n",
              "  'upon',\n",
              "  'his',\n",
              "  'chest',\n",
              "  'and',\n",
              "  'his',\n",
              "  'hands',\n",
              "  'clasped',\n",
              "  'behind',\n",
              "  'him',\n",
              "  'to',\n",
              "  'me',\n",
              "  'who',\n",
              "  'knew',\n",
              "  'his',\n",
              "  'every',\n",
              "  'mood',\n",
              "  'and',\n",
              "  'habit',\n",
              "  'his',\n",
              "  'attitude',\n",
              "  'and',\n",
              "  'manner',\n",
              "  'told',\n",
              "  'their',\n",
              "  'own',\n",
              "  'story',\n",
              "  'he',\n",
              "  'was',\n",
              "  'at',\n",
              "  'work',\n",
              "  'again',\n",
              "  'he',\n",
              "  'had',\n",
              "  'risen',\n",
              "  'out',\n",
              "  'of',\n",
              "  'his',\n",
              "  'drug',\n",
              "  'created',\n",
              "  'dreams',\n",
              "  'and',\n",
              "  'was',\n",
              "  'hot',\n",
              "  'upon',\n",
              "  'the',\n",
              "  'scent',\n",
              "  'of',\n",
              "  'some',\n",
              "  'new',\n",
              "  'problem',\n",
              "  'i',\n",
              "  'rang',\n",
              "  'the',\n",
              "  'bell',\n",
              "  'and',\n",
              "  'was',\n",
              "  'shown',\n",
              "  'up',\n",
              "  'to',\n",
              "  'the',\n",
              "  'chamber',\n",
              "  'which',\n",
              "  'had',\n",
              "  'formerly',\n",
              "  'been',\n",
              "  'in',\n",
              "  'part',\n",
              "  'my',\n",
              "  'own',\n",
              "  'his',\n",
              "  'manner',\n",
              "  'was',\n",
              "  'not',\n",
              "  'effusive',\n",
              "  'it',\n",
              "  'seldom',\n",
              "  'was',\n",
              "  'but',\n",
              "  'he',\n",
              "  'was',\n",
              "  'glad',\n",
              "  'i',\n",
              "  'think',\n",
              "  'to',\n",
              "  'see',\n",
              "  'me',\n",
              "  'with',\n",
              "  'hardly',\n",
              "  'a',\n",
              "  'word',\n",
              "  'spoken',\n",
              "  'but',\n",
              "  'with',\n",
              "  'a',\n",
              "  'kindly',\n",
              "  'eye',\n",
              "  'he',\n",
              "  'waved',\n",
              "  'me',\n",
              "  'to',\n",
              "  'an',\n",
              "  'armchair',\n",
              "  'threw',\n",
              "  'across',\n",
              "  'his',\n",
              "  'case',\n",
              "  'of',\n",
              "  'cigars',\n",
              "  'and',\n",
              "  'indicated',\n",
              "  'a',\n",
              "  'spirit',\n",
              "  'case',\n",
              "  'and',\n",
              "  'a',\n",
              "  'gasogene',\n",
              "  'in',\n",
              "  'the',\n",
              "  'corner',\n",
              "  'then',\n",
              "  'he',\n",
              "  'stood',\n",
              "  'before',\n",
              "  'the',\n",
              "  'fire',\n",
              "  'and',\n",
              "  'looked',\n",
              "  'me',\n",
              "  'over',\n",
              "  'in',\n",
              "  'his',\n",
              "  'singular',\n",
              "  'introspective',\n",
              "  'fashion',\n",
              "  'wedlock',\n",
              "  'suits',\n",
              "  'you',\n",
              "  'he',\n",
              "  'remarked',\n",
              "  'i',\n",
              "  'think',\n",
              "  'watson',\n",
              "  'that',\n",
              "  'you',\n",
              "  'have',\n",
              "  'put',\n",
              "  'on',\n",
              "  'seven',\n",
              "  'and',\n",
              "  'a',\n",
              "  'half',\n",
              "  'pounds',\n",
              "  'since',\n",
              "  'i',\n",
              "  'saw',\n",
              "  'you',\n",
              "  'seven',\n",
              "  'i',\n",
              "  'answered',\n",
              "  'indeed',\n",
              "  'i',\n",
              "  'should',\n",
              "  'have',\n",
              "  'thought',\n",
              "  'a',\n",
              "  'little',\n",
              "  'more',\n",
              "  'just',\n",
              "  'a',\n",
              "  'trifle',\n",
              "  'more',\n",
              "  'i',\n",
              "  'fancy',\n",
              "  'watson',\n",
              "  'and',\n",
              "  'in',\n",
              "  'practice',\n",
              "  'again',\n",
              "  'i',\n",
              "  'observe',\n",
              "  'you',\n",
              "  'did',\n",
              "  'not',\n",
              "  'tell',\n",
              "  'me',\n",
              "  'that',\n",
              "  'you',\n",
              "  'intended',\n",
              "  'to',\n",
              "  'go',\n",
              "  'into',\n",
              "  'harness',\n",
              "  'then',\n",
              "  'how',\n",
              "  'do',\n",
              "  'you',\n",
              "  'know',\n",
              "  'i',\n",
              "  'see',\n",
              "  'it',\n",
              "  'i',\n",
              "  'deduce',\n",
              "  'it',\n",
              "  'how',\n",
              "  'do',\n",
              "  'i',\n",
              "  'know',\n",
              "  'that',\n",
              "  'you',\n",
              "  'have',\n",
              "  'been',\n",
              "  'getting',\n",
              "  'yourself',\n",
              "  'very',\n",
              "  'wet',\n",
              "  'lately',\n",
              "  'and',\n",
              "  'that',\n",
              "  'you',\n",
              "  'have',\n",
              "  'a',\n",
              "  'most',\n",
              "  'clumsy',\n",
              "  'and',\n",
              "  'careless',\n",
              "  'servant',\n",
              "  'girl',\n",
              "  'my',\n",
              "  'dear',\n",
              "  'holmes',\n",
              "  'said',\n",
              "  'i',\n",
              "  'this',\n",
              "  'is',\n",
              "  'too',\n",
              "  'much',\n",
              "  'you',\n",
              "  'would',\n",
              "  'certainly',\n",
              "  'have',\n",
              "  'been',\n",
              "  'burned',\n",
              "  'had',\n",
              "  'you',\n",
              "  'lived',\n",
              "  'a',\n",
              "  'few',\n",
              "  'centuries',\n",
              "  'ago',\n",
              "  'it',\n",
              "  'is',\n",
              "  'true',\n",
              "  'that',\n",
              "  'i',\n",
              "  'had',\n",
              "  'a',\n",
              "  'country',\n",
              "  'walk',\n",
              "  'on',\n",
              "  'thursday',\n",
              "  'and',\n",
              "  'came',\n",
              "  'home',\n",
              "  'in',\n",
              "  'a',\n",
              "  'dreadful',\n",
              "  'mess',\n",
              "  'but',\n",
              "  'as',\n",
              "  'i',\n",
              "  'have',\n",
              "  'changed',\n",
              "  'my',\n",
              "  'clothes',\n",
              "  'i',\n",
              "  'cannot',\n",
              "  'imagine',\n",
              "  'how',\n",
              "  'you',\n",
              "  'deduce',\n",
              "  'it',\n",
              "  'as',\n",
              "  'to',\n",
              "  'mary',\n",
              "  'jane',\n",
              "  'she',\n",
              "  'is',\n",
              "  'incorrigible',\n",
              "  'and',\n",
              "  'my',\n",
              "  'wife',\n",
              "  'has',\n",
              "  'given',\n",
              "  'her',\n",
              "  'notice',\n",
              "  'but',\n",
              "  'there',\n",
              "  'again',\n",
              "  'i',\n",
              "  'fail',\n",
              "  'to',\n",
              "  'see',\n",
              "  'how',\n",
              "  'you',\n",
              "  'work',\n",
              "  'it',\n",
              "  'out',\n",
              "  'he',\n",
              "  'chuckled',\n",
              "  'to',\n",
              "  'himself',\n",
              "  'and',\n",
              "  'rubbed',\n",
              "  'his',\n",
              "  'long',\n",
              "  'nervous',\n",
              "  'hands',\n",
              "  'together',\n",
              "  'it',\n",
              "  'is',\n",
              "  'simplicity',\n",
              "  'itself',\n",
              "  'said',\n",
              "  'he',\n",
              "  'my',\n",
              "  'eyes',\n",
              "  'tell',\n",
              "  'me',\n",
              "  'that',\n",
              "  'on',\n",
              "  'the',\n",
              "  'inside',\n",
              "  'of',\n",
              "  'your',\n",
              "  'left',\n",
              "  'shoe',\n",
              "  'just',\n",
              "  'where',\n",
              "  'the',\n",
              "  'firelight',\n",
              "  'strikes',\n",
              "  'it',\n",
              "  'the',\n",
              "  'leather',\n",
              "  'is',\n",
              "  'scored',\n",
              "  'by',\n",
              "  'six',\n",
              "  'almost',\n",
              "  'parallel',\n",
              "  'cuts',\n",
              "  'obviously',\n",
              "  'they',\n",
              "  'have',\n",
              "  'been',\n",
              "  'caused',\n",
              "  'by',\n",
              "  'someone',\n",
              "  'who',\n",
              "  'has',\n",
              "  'very',\n",
              "  'carelessly',\n",
              "  'scraped',\n",
              "  'round',\n",
              "  'the',\n",
              "  'edges',\n",
              "  'of',\n",
              "  'the',\n",
              "  'sole',\n",
              "  'in',\n",
              "  'order',\n",
              "  'to',\n",
              "  'remove',\n",
              "  'crusted',\n",
              "  'mud',\n",
              "  'from',\n",
              "  'it',\n",
              "  'hence',\n",
              "  'you',\n",
              "  'see',\n",
              "  'my',\n",
              "  'double',\n",
              "  'deduction',\n",
              "  'that',\n",
              "  'you',\n",
              "  'had',\n",
              "  'been',\n",
              "  'out',\n",
              "  'in',\n",
              "  'vile',\n",
              "  'weather',\n",
              "  'and',\n",
              "  'that',\n",
              "  'you',\n",
              "  'had',\n",
              "  'a',\n",
              "  'particularly',\n",
              "  'malignant',\n",
              "  'boot',\n",
              "  'slitting',\n",
              "  'specimen',\n",
              "  'of',\n",
              "  'the',\n",
              "  'london',\n",
              "  'slavey',\n",
              "  'as',\n",
              "  'to',\n",
              "  'your',\n",
              "  'practice',\n",
              "  'if',\n",
              "  'a',\n",
              "  'gentleman',\n",
              "  'walks',\n",
              "  'into',\n",
              "  'my',\n",
              "  'rooms',\n",
              "  'smelling',\n",
              "  'of',\n",
              "  'iodoform',\n",
              "  'with',\n",
              "  'a',\n",
              "  'black',\n",
              "  'mark',\n",
              "  'of',\n",
              "  'nitrate',\n",
              "  'of',\n",
              "  'silver',\n",
              "  'upon',\n",
              "  'his',\n",
              "  'right',\n",
              "  'forefinger',\n",
              "  'and',\n",
              "  'a',\n",
              "  'bulge',\n",
              "  'on',\n",
              "  'the',\n",
              "  'right',\n",
              "  'side',\n",
              "  'of',\n",
              "  'his',\n",
              "  'top',\n",
              "  'hat',\n",
              "  'to',\n",
              "  'show',\n",
              "  'where',\n",
              "  'he',\n",
              "  'has',\n",
              "  ...]]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 - Crear los vectores (word2vec)"
      ],
      "metadata": {
        "id": "i1WH3HqvqMnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "\n",
        "# class LossCallback(CallbackAny2Vec):\n",
        "#     \"\"\"\n",
        "#     Callback to print loss after each epoch in Gensim training.\n",
        "#     \"\"\"\n",
        "#     def __init__(self):\n",
        "#         self.epoch = 0\n",
        "#         self.loss_previous_step = 0\n",
        "\n",
        "#     def on_epoch_end(self, model):\n",
        "#         if hasattr(model, 'running_training_loss'):  # Newer gensim versions\n",
        "#             loss = model.running_training_loss\n",
        "#         else:\n",
        "#             loss = None  # Fallback if attribute is missing (should not happen in modern gensim)\n",
        "\n",
        "#         if loss is not None:\n",
        "#             print(f'Loss after epoch {self.epoch}: {loss - self.loss_previous_step}')\n",
        "#             self.loss_previous_step = loss\n",
        "#         else:\n",
        "#             print(f'Loss after epoch {self.epoch}: Loss tracking is unavailable')\n",
        "\n",
        "#         self.epoch += 1\n",
        "\n",
        "class callback(CallbackAny2Vec):\n",
        "    \"\"\"\n",
        "    Callback to print loss after each epoch\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        loss = model.get_latest_training_loss()\n",
        "        if self.epoch == 0:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        else:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
        "        self.epoch += 1\n",
        "        self.loss_previous_step = loss"
      ],
      "metadata": {
        "id": "JPjIYXPWqMKP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "# Crearmos el modelo generador de vectores\n",
        "# En este caso utilizaremos la estructura modelo Skipgram\n",
        "w2v_model = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                     window=2,       # cant de palabras antes y desp de la predicha\n",
        "                     vector_size=300,       # dimensionalidad de los vectores\n",
        "                     negative=20,    # cantidad de negative samples... 0 es no se usa\n",
        "                     workers=1,      # si tienen más cores pueden cambiar este valor\n",
        "                     sg=1)           # modelo 0:CBOW  1:skipgram"
      ],
      "metadata": {
        "id": "i7f1XjAK2KLe"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el vocabulario con los tokens\n",
        "w2v_model.build_vocab(sentence_tokens)"
      ],
      "metadata": {
        "id": "2yPvxBmO2S_x"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", w2v_model.corpus_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-4gpWYk2VSH",
        "outputId": "487d7385-41d8-48d0-ef6d-bce7badb4394"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de docs en el corpus: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cantidad de words encontradas en el corpus\n",
        "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model.wv.index_to_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJBl2MGx2YQN",
        "outputId": "eb2048aa-503c-4afb-b107-992a02bfc100"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de words distintas en el corpus: 2052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 - Entrenar embeddings"
      ],
      "metadata": {
        "id": "PLfpd8Jj2a4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo generador de vectores\n",
        "# Utilizamos nuestro callback\n",
        "w2v_model.train(sentence_tokens,\n",
        "                 total_examples=w2v_model.corpus_count,\n",
        "                 epochs=20,\n",
        "                 compute_loss = True,\n",
        "                 callbacks=[callback()]\n",
        "                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEZoUx_o2b0X",
        "outputId": "cfc214ba-4b50-4c11-d8f6-539d824e7685"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after epoch 0: 272221.15625\n",
            "Loss after epoch 1: 138067.21875\n",
            "Loss after epoch 2: 123256.5625\n",
            "Loss after epoch 3: 119673.25\n",
            "Loss after epoch 4: 117552.0\n",
            "Loss after epoch 5: 118267.6875\n",
            "Loss after epoch 6: 117914.9375\n",
            "Loss after epoch 7: 111598.9375\n",
            "Loss after epoch 8: 108608.5\n",
            "Loss after epoch 9: 108995.875\n",
            "Loss after epoch 10: 107929.0\n",
            "Loss after epoch 11: 107817.5\n",
            "Loss after epoch 12: 107645.25\n",
            "Loss after epoch 13: 107047.875\n",
            "Loss after epoch 14: 107318.375\n",
            "Loss after epoch 15: 107526.5\n",
            "Loss after epoch 16: 107509.75\n",
            "Loss after epoch 17: 89113.875\n",
            "Loss after epoch 18: 87625.0\n",
            "Loss after epoch 19: 87397.75\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 2117600)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4 - Ensayar"
      ],
      "metadata": {
        "id": "Rcdu2Q7O3GQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"sherlock\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndwnSBEq3FlO",
        "outputId": "5417d66c-f544-4919-c290-76d6d1266f3e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('jabez', 0.9801268577575684),\n",
              " ('wilson', 0.9648646116256714),\n",
              " ('said', 0.9618110656738281),\n",
              " ('duncan', 0.9512567520141602),\n",
              " ('merryweather', 0.9472882747650146),\n",
              " ('mr', 0.9443387985229492),\n",
              " ('ross', 0.9239485263824463),\n",
              " ('holmes', 0.9206176400184631),\n",
              " ('now', 0.9149553179740906),\n",
              " ('asked', 0.9149285554885864)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}