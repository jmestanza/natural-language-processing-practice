{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmestanza/natural-language-processing-practice/blob/main/desafios/Desafio_3/Desafio_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desafío 3\n",
        "Entrenar un modelo de lenguaje basado en caracteres utilizando la [notebook](https://github.com/jmestanza/procesamiento_lenguaje_natural/blob/main/clase_3/ejercicios/3_modelo_lenguaje_char.ipynb) de clase como base .\n",
        "\n",
        "Objetivos principales\n",
        "- Comprender el modelo de lenguaje basado en caracteres.\n",
        "- Definir un corpus para entrenar el modelo.\n",
        "- Tomar decisiones sobre la arquitectura del modelo.\n",
        "- Ejecutar el entrenamiento y analizar los resultados.\n",
        "- Generar secuencias de texto utilizando el modelo entrenado.\n",
        "\n",
        "\n",
        "Se define un vocabulario de caracteres, incluyendo letras, signos de puntuación y espacios.\n",
        "\n",
        "Se crean diccionarios de tokenización (carácter a índice y viceversa).\n",
        "\n",
        "El modelo se entrena en un esquema many-to-many, donde la entrada es una secuencia de caracteres y la salida es la misma secuencia desplazada en un carácter.\n",
        "\n",
        "Se menciona el uso de capa embedding y time-distributed layers para manejar secuencias.\n",
        "\n",
        "Generación de texto\n",
        "Se propone experimentar con diferentes estrategias de generación de secuencias.\n",
        "\n",
        "Se pueden probar enfoques deterministas o estocásticos para generar texto.\n",
        "\n",
        "Se debe documentar los resultados de generación obtenidos con el modelo final.\n",
        "\n",
        "Entrega esperada\n",
        "Modelo de lenguaje entrenado con la arquitectura seleccionada.\n",
        "\n",
        "Ejemplos de generación de texto con el modelo.\n",
        "\n",
        "Reflexión sobre los resultados y ajustes realizados.\n",
        "\n",
        "En resumen, el trabajo implica entrenar un modelo de lenguaje basado en caracteres, ajustar su arquitectura, medir su rendimiento y generar texto con él."
      ],
      "metadata": {
        "id": "JGWTDDTSXMWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "Originalmente, se había optado por el dataset `THE COMPLETE SHERLOCK HOLMES` que tiene todo el canon de los libros de Arthur Conan Doyle. Pero debido a que es un corpus muy grande  (3868122 de caracteres), la sesión se queda sin ram. Por lo cual se optó por un corpus más chico `The Adventures of Sherlock Holmes` (581565 caracteres)."
      ],
      "metadata": {
        "id": "qnJwd89JZ32_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "dataset_path = 'the_adventures_of_sherlock_holmes.txt'\n",
        "if not os.path.exists(dataset_path):\n",
        "  # !wget https://raw.githubusercontent.com/jmestanza/natural-language-processing-practice/refs/heads/main/desafios/Desafio_2/cano.txt\n",
        "  !wget https://raw.githubusercontent.com/jmestanza/natural-language-processing-practice/refs/heads/main/desafios/Desafio_2/the_adventures_of_sherlock_holmes.txt"
      ],
      "metadata": {
        "id": "2s4QTbQwXP-m",
        "outputId": "c8b70db0-48cb-47e5-89d2-769acc5d3e0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-08 02:55:56--  https://raw.githubusercontent.com/jmestanza/natural-language-processing-practice/refs/heads/main/desafios/Desafio_2/the_adventures_of_sherlock_holmes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607648 (593K) [text/plain]\n",
            "Saving to: ‘the_adventures_of_sherlock_holmes.txt’\n",
            "\n",
            "the_adventures_of_s 100%[===================>] 593.41K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-04-08 02:55:57 (17.8 MB/s) - ‘the_adventures_of_sherlock_holmes.txt’ saved [607648/607648]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(dataset_path, 'r') as f:\n",
        "  text = f.read()\n",
        "\n",
        "print(len(text))\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKvsSbtjak1-",
        "outputId": "0763c04f-1a4e-464b-f161-775d46295a28"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "581565\n",
            "﻿The Project Gutenberg eBook of The Adventures of Sherlock Holmes\n",
            "    \n",
            "This ebook is for the use of anyone anywhere in the United States and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\n",
            "of the Project Gutenberg License included with this ebook or online\n",
            "at www.gutenberg.org. If you are not located in the United States,\n",
            "you will have to check the laws of the country where you are located\n",
            "before using this eBook.\n",
            "\n",
            "Title: The Adventures of Sherlock Holmes\n",
            "\n",
            "Author: Arthur Conan Doyle\n",
            "\n",
            "Release date: March 1, 1999 [eBook #1661]\n",
            "                Most recently updated: October 10, 2023\n",
            "\n",
            "Language: English\n",
            "\n",
            "Credits: an anonymous Project Gutenberg volunteer and Jose Menendez\n",
            "\n",
            "\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK THE ADVENTURES OF SHERLOCK HOLMES ***\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The Adventures of Sherlock Holmes\n",
            "\n",
            "by Arthur Conan Doyle\n",
            "\n",
            "\n",
            "Contents\n",
            "\n",
            "   I.     A Scandal in Bohemia\n",
            "   II.    The Red-Headed League\n",
            "   III.   A \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus de texto puede ser considerado un documento en sí mismo y el tamaño de contexto puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ],
      "metadata": {
        "id": "uj17kqEPat1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100\n",
        "\n",
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding\n",
        "\n",
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(text)\n",
        "\n",
        "# la longitud de vocabulario de caracteres es:\n",
        "print(len(chars_vocab))\n",
        "\n",
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}\n"
      ],
      "metadata": {
        "id": "2TFAHyg9ar9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f221cf-8851-426a-bca2-4063063111c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizar"
      ],
      "metadata": {
        "id": "oalbHoONbH2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in text]\n",
        "tokenized_text[:25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnzWy8DRbHZ_",
        "outputId": "dc5f91fd-bee5-40aa-a56f-6696ea223060"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[67,\n",
              " 86,\n",
              " 22,\n",
              " 9,\n",
              " 81,\n",
              " 82,\n",
              " 71,\n",
              " 70,\n",
              " 11,\n",
              " 9,\n",
              " 19,\n",
              " 30,\n",
              " 81,\n",
              " 6,\n",
              " 8,\n",
              " 30,\n",
              " 9,\n",
              " 40,\n",
              " 15,\n",
              " 9,\n",
              " 71,\n",
              " 33,\n",
              " 81,\n",
              " 9,\n",
              " 21]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Organizando y estructurando el dataset"
      ],
      "metadata": {
        "id": "N8WVQ3vhbUrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ],
      "metadata": {
        "id": "foxYzdbFbY0o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ],
      "metadata": {
        "id": "imGkGH92bb4y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]\n",
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ],
      "metadata": {
        "id": "aJElgNmbbdoX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(tokenized_sentences_train[:-1])\n",
        "y_train = np.array(tokenized_sentences_train[1:])"
      ],
      "metadata": {
        "id": "uXTAOxNRbf6j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokenized_sentences_val))\n",
        "print(len(tokenized_sentences_val[0]))"
      ],
      "metadata": {
        "id": "icyWJhW4lNrn",
        "outputId": "396503ea-e2e5-4d4e-c6ef-625232397cb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "582\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como many-to-many:\n",
        "\n",
        "Entrada: secuencia de tokens $[x_0,x_1, ..., x_n]$\n",
        "\n",
        "Target: secuencia de tokens $[x_1,x_2, ...,x_{n+1}]$\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como many-to-one en donde sólo una señal de gradiente se propaga."
      ],
      "metadata": {
        "id": "Jh5er4kQcRxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este punto tenemos en la variable tokenized_sentences los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ],
      "metadata": {
        "id": "S6JOyq3Qcj1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjthpqMrcip3",
        "outputId": "c9c1ad4c-a0bd-4384-c330-84c41e7fe882"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(523265, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0,:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsan6E-vcnfC",
        "outputId": "79a9fabe-64ac-48d4-ed89-e44137ea6d56"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([67, 86, 22,  9, 81, 82, 71, 70, 11,  9])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0,:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjsC_PzMcqo_",
        "outputId": "9bdd3c9e-0f3b-400e-acba-7a0947dacdd4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([86, 22,  9, 81, 82, 71, 70, 11,  9, 19])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(chars_vocab)\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he78PmZcct-L",
        "outputId": "3764eacc-2822-4f95-c1e7-bc03710ecf96"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definiendo el modelo"
      ],
      "metadata": {
        "id": "6fSc4ocPcw7K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas CategoryEncoding que transforma a índices a vectores OHE y TimeDistributed que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia."
      ],
      "metadata": {
        "id": "-U8-Umk8c2aW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
        "from keras.models import Model, Sequential\n",
        "model = Sequential([\n",
        "    Input(shape=(None, 1)),\n",
        "    TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode=\"one_hot\")),\n",
        "    SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1),\n",
        "    Dense(vocab_size, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "T2gwQ1G9c13E",
        "outputId": "a77190d2-1834-42a3-8b9f-411171ccf0c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)           │          \u001b[38;5;34m59,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │          \u001b[38;5;34m19,698\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">59,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,698</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,498\u001b[0m (310.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,498</span> (310.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,498\u001b[0m (310.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,498</span> (310.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perplexity callback"
      ],
      "metadata": {
        "id": "1qlDvuRzdL3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se tuvo que cambiar el enfoque de la implementación del cálculo de perplexity a un enfoque de tipo `batch` ya que la sesión de Colab se terminaba por quedarse sin memoria."
      ],
      "metadata": {
        "id": "BS8tVBL4CvB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "class PplCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, val_data, history_ppl, patience=5, batch_size=512, eval_every=1):\n",
        "        self.batch_size = batch_size\n",
        "        self.patience = patience\n",
        "        self.eval_every = eval_every\n",
        "        self.history_ppl = history_ppl\n",
        "        self.times = []\n",
        "\n",
        "        self.min_score = np.inf\n",
        "        self.patience_counter = 0\n",
        "\n",
        "        self.sequences = []\n",
        "        self.targets = []\n",
        "        self.splits = []\n",
        "        idx = 0\n",
        "\n",
        "        for seq in val_data:\n",
        "            if len(seq) <= 1:\n",
        "                continue\n",
        "            subseq = [seq[:i] for i in range(1, len(seq))]\n",
        "            target = [seq[i] for i in range(1, len(seq))]\n",
        "\n",
        "            self.sequences.extend(subseq)\n",
        "            self.targets.extend(target)\n",
        "            self.splits.append((idx, idx + len(subseq)))\n",
        "            idx += len(subseq)\n",
        "\n",
        "        self.targets = np.array(self.targets)\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        elapsed = time.time() - self.start_time\n",
        "        self.times.append(elapsed)\n",
        "        print(f\"\\nEpoch {epoch + 1} took {elapsed:.2f} seconds\")\n",
        "\n",
        "        # Only evaluate every N epochs\n",
        "        if (epoch + 1) % self.eval_every != 0:\n",
        "            print(\"Skipping perplexity evaluation this epoch.\")\n",
        "            self.history_ppl.append(None)  # placeholder\n",
        "            return\n",
        "\n",
        "        start_time = time.time()\n",
        "        print(\"\\nEvaluating perplexity on validation set...\")\n",
        "        preds_all = []\n",
        "\n",
        "        for i in range(0, len(self.sequences), self.batch_size):\n",
        "            batch_seqs = self.sequences[i:i+self.batch_size]\n",
        "            padded = pad_sequences(batch_seqs, maxlen=max_context_size, padding='pre')\n",
        "            preds = self.model.predict(padded, verbose=0)[:, -1, :]  # last step only\n",
        "            preds_all.append(preds)\n",
        "\n",
        "        predictions = np.vstack(preds_all)\n",
        "        chosen_probs = predictions[np.arange(len(predictions)), self.targets]\n",
        "        log_probs = np.log(chosen_probs + 1e-10)\n",
        "\n",
        "        scores = []\n",
        "        for start, end in self.splits:\n",
        "            mean_log_prob = np.mean(log_probs[start:end])\n",
        "            scores.append(np.exp(-mean_log_prob))\n",
        "\n",
        "        current_score = np.mean(scores)\n",
        "        self.history_ppl.append(current_score)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f'\\nMean Perplexity: {current_score:.4f} | Evaluation Time: {elapsed:.2f} seconds\\n')\n",
        "\n",
        "        if current_score < self.min_score:\n",
        "            self.min_score = current_score\n",
        "            self.model.save(\"my_model.keras\")\n",
        "            print(\"Saved new best model.\")\n",
        "            self.patience_counter = 0\n",
        "        else:\n",
        "            self.patience_counter += 1\n",
        "            if self.patience_counter >= self.patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                self.model.stop_training = True\n"
      ],
      "metadata": {
        "id": "LPZzuUBFkz0_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento"
      ],
      "metadata": {
        "id": "V8p5ErXYdWVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "# batch_size = 512 -> 61 segs perplex calc time\n",
        "# batch_size = 1024 -> 50 segs perplex calc time\n",
        "# batch_size = 2048 -> 43 segs perplex calc time <-- nos quedamos con este porque usa menos memoria y el beneficio en tiempo es aprox la misma que 4096\n",
        "# batch_size = 4096 -> 41.44 segs perplex calc time\n",
        "ppl_cb = PplCallback(val_data=tokenized_sentences_val, history_ppl=history_ppl, batch_size=2048)\n",
        "model.fit(X_train, y_train, epochs=20, callbacks=[ppl_cb], batch_size=1024)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "VbUBcxs6V9fV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Epoch 1/20\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - loss: 2.2485\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 10.9563 | Evaluation Time: 36.94 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 61s 115ms/step - loss: 2.2484\n",
        "Epoch 2/20\n",
        "510/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 2.0832\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 9.7245 | Evaluation Time: 35.89 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 76s 108ms/step - loss: 2.0830\n",
        "Epoch 3/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.9803\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 9.1274 | Evaluation Time: 35.50 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 55s 107ms/step - loss: 1.9803\n",
        "Epoch 4/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.9175\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.9740 | Evaluation Time: 37.15 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 84s 111ms/step - loss: 1.9174\n",
        "Epoch 5/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.8755\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.7260 | Evaluation Time: 36.53 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 56s 110ms/step - loss: 1.8754\n",
        "Epoch 6/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - loss: 1.8465\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.4781 | Evaluation Time: 37.64 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 83s 112ms/step - loss: 1.8465\n",
        "Epoch 7/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - loss: 1.8236\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.4720 | Evaluation Time: 35.53 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 80s 108ms/step - loss: 1.8236\n",
        "Epoch 8/20\n",
        "510/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.8069\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.5718 | Evaluation Time: 36.44 seconds\n",
        "\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 83s 110ms/step - loss: 1.8069\n",
        "Epoch 9/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7931\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.1454 | Evaluation Time: 35.76 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 55s 108ms/step - loss: 1.7931\n",
        "Epoch 10/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7810\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.2308 | Evaluation Time: 39.07 seconds\n",
        "\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 59s 115ms/step - loss: 1.7810\n",
        "Epoch 11/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7707\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.3993 | Evaluation Time: 36.41 seconds\n",
        "\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 79s 110ms/step - loss: 1.7707\n",
        "Epoch 12/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7633\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 7.4498 | Evaluation Time: 38.13 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 84s 113ms/step - loss: 1.7633\n",
        "Epoch 13/20\n",
        "510/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7554\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.3274 | Evaluation Time: 36.81 seconds\n",
        "\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 81s 110ms/step - loss: 1.7554\n",
        "Epoch 14/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7504\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.4714 | Evaluation Time: 38.36 seconds\n",
        "\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 83s 113ms/step - loss: 1.7504\n",
        "Epoch 15/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7443\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.5419 | Evaluation Time: 37.85 seconds\n",
        "\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 81s 112ms/step - loss: 1.7443\n",
        "Epoch 16/20\n",
        "510/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7386\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 7.9335 | Evaluation Time: 38.13 seconds\n",
        "\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 82s 113ms/step - loss: 1.7386\n",
        "Epoch 17/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7351\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 7.7394 | Evaluation Time: 35.64 seconds\n",
        "\n",
        "Early stopping triggered.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 79s 108ms/step - loss: 1.7351\n",
        "<keras.src.callbacks.history.History at 0x7c1d405cded0>\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "f5AKTOF7WPm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Zx7LpKR_WXID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "WCiudkIjWl03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model = keras.models.load_model('my_model.keras')"
      ],
      "metadata": {
        "id": "p3XMbs6kz-vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicción del próximo caracter"
      ],
      "metadata": {
        "id": "w0eCJTcO0Cii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q gradio\n",
        "# import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "# iface = gr.Interface(\n",
        "#     fn=model_response,\n",
        "#     inputs=[\"textbox\"],\n",
        "#     outputs=\"text\")\n",
        "\n",
        "# iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "gOV5N1Wa0IiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_response('Sherloc')"
      ],
      "metadata": {
        "id": "YzIWLtim1vYH",
        "outputId": "d42bb6e2-3689-4016-deac-5ee25625a48a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sherlock'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_response('Holme')"
      ],
      "metadata": {
        "id": "3fGjoZqN1y_N",
        "outputId": "fdab4940-1561-4b4b-a3ce-78cb70502348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Holmes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_response('Dr. Watso')"
      ],
      "metadata": {
        "id": "CviF4FYQ106B",
        "outputId": "fcc50ef7-aa87-4812-b1db-4030de0d59ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dr. Watson'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq = \"Sherlo\"\n",
        "for i in range(10):\n",
        "  seq = model_response(seq)\n",
        "  print(seq)"
      ],
      "metadata": {
        "id": "AhwdkiCB2pQq",
        "outputId": "e39832d5-2f1b-4ce5-c7b7-056648443cfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "Sherloc\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
            "Sherlock\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
            "Sherlock \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
            "Sherlock H\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Sherlock Ha\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Sherlock Had\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Sherlock Had \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Sherlock Had b\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Sherlock Had be\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Sherlock Had bee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq = \"Dr. Wats\"\n",
        "for i in range(10):\n",
        "  seq = model_response(seq)\n",
        "  print(seq)"
      ],
      "metadata": {
        "id": "rjbpcKcS2QeA",
        "outputId": "41f48425-bee2-42d7-80b9-e03a3438024d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "Dr. Watso\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "Dr. Watson\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
            "Dr. Watson,\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Dr. Watson, \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Dr. Watson, a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Dr. Watson, an\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Dr. Watson, and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Dr. Watson, and \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Dr. Watson, and a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Dr. Watson, and a \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación de secuencias"
      ],
      "metadata": {
        "id": "jDw6fhJp2_RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text\n"
      ],
      "metadata": {
        "id": "x0vurrET3Bot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text='Sherlock'\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ],
      "metadata": {
        "id": "XkdEqj4x3FGu",
        "outputId": "95fd805f-5a72-4bbb-ef92-823517ebe553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sherlock Had been and a looked and a l'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text='Dr. Wats'\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ],
      "metadata": {
        "id": "Cke3ib0L3ZmP",
        "outputId": "2be3083e-f5ff-4c98-919f-ce539b9e8641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dr. Watson, and a looked and a looked '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beam search y muestreo aleatorio"
      ],
      "metadata": {
        "id": "nMZ5yX97QsCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ],
      "metadata": {
        "id": "PeOyq1gRQrN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ],
      "metadata": {
        "id": "1aSDN5XKQuaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=20,input=\"Sherlock Holmes\")"
      ],
      "metadata": {
        "id": "TyqDgbwNQxh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "salidas[0]\n"
      ],
      "metadata": {
        "id": "G5CcLhGNQ4lp",
        "outputId": "22e985f7-c07e-4e63-ad77-3b00b7ba353c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([60, 25, 10, 80, 47, 79, 72, 81, 84, 18, 79, 47, 26, 10, 96, 24, 84,\n",
              "       56, 66, 34, 84, 40, 84, 96, 25, 79, 68, 47, 34, 84, 66, 79, 12, 84,\n",
              "       56])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[0])"
      ],
      "metadata": {
        "id": "yZpvdfdXQ6kn",
        "outputId": "82363cb7-1c99-4aa8-c66e-03410c415643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sherlock Holmes, and I should not a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analizamos el caso de utilizar una LSTM o GRU\n",
        "\n",
        "Nótese que seteamos `recurrent_dropout=0.0` para estos nuevos casos,\n",
        "esto es porque hacerlo nos permite utilizar CuDNN, lo cual reduce drásticamente los tiempos de entrenamiento para esos modelos. Realizando pruebas pasó el tiempo por epoch de 140 segundos a 20 segundos en el caso de LSTM, es decir 7 veces menos tardó en total.\n",
        "\n",
        "Podemos acelerar aún más el tiempo de entrenamiento utilizando\n",
        "```\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "```\n",
        "Que si bien redujo el tiempo por epoch para LSTM, lo redujo de 20 a 15 segundos a cambio de una pérdida en la precisión.\n",
        "\n",
        "Es por eso que se decide preservar la configuración por defecto teniendo más precisión sobre los cálculos."
      ],
      "metadata": {
        "id": "wWbGkCVgRn7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import SimpleRNN, LSTM, GRU, Input, TimeDistributed, CategoryEncoding, Dense\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "\n",
        "cfg_model = {\n",
        "    # \"SimpleRNN\": {\"units\": 200, \"recurrent_dropout\": 0.1},\n",
        "    \"LSTM\": {\"units\": 92, \"recurrent_dropout\": 0.0},  # ~comparable params to SimpleRNN\n",
        "    \"GRU\": {\"units\": 109, \"recurrent_dropout\": 0.0}    # somewhere in between\n",
        "}\n",
        "\n",
        "all_models = {}\n",
        "for model in [\n",
        "    # SimpleRNN,\n",
        "              LSTM, GRU]:\n",
        "    complete_model = Sequential([\n",
        "        Input(shape=(None, 1)),\n",
        "        TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode=\"one_hot\")),\n",
        "        model(**cfg_model[model.__name__], return_sequences=True, dropout=0.1),\n",
        "        Dense(vocab_size, activation=\"softmax\")\n",
        "    ])\n",
        "    complete_model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "    all_models[model.__name__] = complete_model\n",
        "    print(complete_model.summary())"
      ],
      "metadata": {
        "id": "_7zfaX89Rq22",
        "outputId": "694d9d44-b1d4-41bd-e760-b146cc74c432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_2 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m92\u001b[0m)            │          \u001b[38;5;34m70,288\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │           \u001b[38;5;34m9,114\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">70,288</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,114</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,402\u001b[0m (310.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,402</span> (310.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,402\u001b[0m (310.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,402</span> (310.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_3 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m)           │          \u001b[38;5;34m68,343\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │          \u001b[38;5;34m10,780\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">68,343</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,780</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,123\u001b[0m (309.07 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,123</span> (309.07 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,123\u001b[0m (309.07 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,123</span> (309.07 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "all_perplexities = {}\n",
        "for name, curr_model in all_models.items():\n",
        "    print(f\"Using model with {name}\")\n",
        "    history_ppl = []\n",
        "    ppl_cb = PplCallback(val_data=tokenized_sentences_val, history_ppl=history_ppl, batch_size=2048, eval_every=5)\n",
        "    curr_model.fit(X_train, y_train, epochs=20, callbacks=[ppl_cb], batch_size=1024)\n",
        "    all_perplexities[model.__name__] = history_ppl"
      ],
      "metadata": {
        "id": "D2KKR2aDRvzy",
        "outputId": "4bf15bd0-b0b3-4efb-a2ae-97d6f4af1826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using model with LSTM\n",
            "Epoch 1/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.2008\n",
            "Epoch 1 took 23.60 seconds\n",
            "Skipping perplexity evaluation this epoch.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - loss: 3.2003\n",
            "Epoch 2/20\n",
            "\u001b[1m510/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.5698\n",
            "Epoch 2 took 15.68 seconds\n",
            "Skipping perplexity evaluation this epoch.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 31ms/step - loss: 2.5695\n",
            "Epoch 3/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.4138\n",
            "Epoch 3 took 20.50 seconds\n",
            "Skipping perplexity evaluation this epoch.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - loss: 2.4137\n",
            "Epoch 4/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.3381\n",
            "Epoch 4 took 15.78 seconds\n",
            "Skipping perplexity evaluation this epoch.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 31ms/step - loss: 2.3381\n",
            "Epoch 5/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.2824\n",
            "Epoch 5 took 15.54 seconds\n",
            "\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 14.4688 | Evaluation Time: 51.94 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 132ms/step - loss: 2.2823\n",
            "Epoch 6/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.2329\n",
            "Epoch 6 took 15.90 seconds\n",
            "Skipping perplexity evaluation this epoch.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 31ms/step - loss: 2.2328\n",
            "Epoch 7/20\n",
            "\u001b[1m425/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 2.1910"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-08735e55ebd6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhistory_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mppl_cb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPplCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenized_sentences_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_ppl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory_ppl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcurr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mppl_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mall_perplexities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_ppl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If memory becomes an issue, try using an Embedding layer instead. Less RAM usage, more compact representation."
      ],
      "metadata": {
        "id": "_kSjkWC0SGcW"
      }
    }
  ]
}