{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmestanza/natural-language-processing-practice/blob/main/desafios/Desafio_3/Desafio_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desafío 3\n",
        "Entrenar un modelo de lenguaje basado en caracteres utilizando la [notebook](https://github.com/jmestanza/procesamiento_lenguaje_natural/blob/main/clase_3/ejercicios/3_modelo_lenguaje_char.ipynb) de clase como base .\n",
        "\n",
        "Objetivos principales\n",
        "- Comprender el modelo de lenguaje basado en caracteres.\n",
        "- Definir un corpus para entrenar el modelo.\n",
        "- Tomar decisiones sobre la arquitectura del modelo.\n",
        "- Ejecutar el entrenamiento y analizar los resultados.\n",
        "- Generar secuencias de texto utilizando el modelo entrenado.\n",
        "\n",
        "\n",
        "Se define un vocabulario de caracteres, incluyendo letras, signos de puntuación y espacios.\n",
        "\n",
        "Se crean diccionarios de tokenización (carácter a índice y viceversa).\n",
        "\n",
        "El modelo se entrena en un esquema many-to-many, donde la entrada es una secuencia de caracteres y la salida es la misma secuencia desplazada en un carácter.\n",
        "\n",
        "Se menciona el uso de capa embedding y time-distributed layers para manejar secuencias.\n",
        "\n",
        "Generación de texto\n",
        "Se propone experimentar con diferentes estrategias de generación de secuencias.\n",
        "\n",
        "Se pueden probar enfoques deterministas o estocásticos para generar texto.\n",
        "\n",
        "Se debe documentar los resultados de generación obtenidos con el modelo final.\n",
        "\n",
        "Entrega esperada\n",
        "Modelo de lenguaje entrenado con la arquitectura seleccionada.\n",
        "\n",
        "Ejemplos de generación de texto con el modelo.\n",
        "\n",
        "Reflexión sobre los resultados y ajustes realizados.\n",
        "\n",
        "En resumen, el trabajo implica entrenar un modelo de lenguaje basado en caracteres, ajustar su arquitectura, medir su rendimiento y generar texto con él."
      ],
      "metadata": {
        "id": "JGWTDDTSXMWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "Originalmente, se había optado por el dataset `THE COMPLETE SHERLOCK HOLMES` que tiene todo el canon de los libros de Arthur Conan Doyle. Pero debido a que es un corpus muy grande  (3868122 de caracteres), la sesión se queda sin ram. Por lo cual se optó por un corpus más chico `The Adventures of Sherlock Holmes` (581565 caracteres)."
      ],
      "metadata": {
        "id": "qnJwd89JZ32_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "dataset_path = 'the_adventures_of_sherlock_holmes.txt'\n",
        "if not os.path.exists(dataset_path):\n",
        "  # !wget https://raw.githubusercontent.com/jmestanza/natural-language-processing-practice/refs/heads/main/desafios/Desafio_2/cano.txt\n",
        "  !wget https://raw.githubusercontent.com/jmestanza/natural-language-processing-practice/refs/heads/main/desafios/Desafio_2/the_adventures_of_sherlock_holmes.txt"
      ],
      "metadata": {
        "id": "2s4QTbQwXP-m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(dataset_path, 'r') as f:\n",
        "  text = f.read()\n",
        "\n",
        "print(len(text))\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKvsSbtjak1-",
        "outputId": "7d60202f-3c94-4f82-e07b-ba2d2aff3eaf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "581565\n",
            "﻿The Project Gutenberg eBook of The Adventures of Sherlock Holmes\n",
            "    \n",
            "This ebook is for the use of anyone anywhere in the United States and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\n",
            "of the Project Gutenberg License included with this ebook or online\n",
            "at www.gutenberg.org. If you are not located in the United States,\n",
            "you will have to check the laws of the country where you are located\n",
            "before using this eBook.\n",
            "\n",
            "Title: The Adventures of Sherlock Holmes\n",
            "\n",
            "Author: Arthur Conan Doyle\n",
            "\n",
            "Release date: March 1, 1999 [eBook #1661]\n",
            "                Most recently updated: October 10, 2023\n",
            "\n",
            "Language: English\n",
            "\n",
            "Credits: an anonymous Project Gutenberg volunteer and Jose Menendez\n",
            "\n",
            "\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK THE ADVENTURES OF SHERLOCK HOLMES ***\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The Adventures of Sherlock Holmes\n",
            "\n",
            "by Arthur Conan Doyle\n",
            "\n",
            "\n",
            "Contents\n",
            "\n",
            "   I.     A Scandal in Bohemia\n",
            "   II.    The Red-Headed League\n",
            "   III.   A \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus de texto puede ser considerado un documento en sí mismo y el tamaño de contexto puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ],
      "metadata": {
        "id": "uj17kqEPat1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100\n",
        "\n",
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding\n",
        "\n",
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(text)\n",
        "\n",
        "# la longitud de vocabulario de caracteres es:\n",
        "print(len(chars_vocab))\n",
        "\n",
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}\n"
      ],
      "metadata": {
        "id": "2TFAHyg9ar9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1db72bb-7de1-4d6b-9fc7-bf0138fa0607"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizar"
      ],
      "metadata": {
        "id": "oalbHoONbH2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in text]\n",
        "tokenized_text[:25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnzWy8DRbHZ_",
        "outputId": "9ea73cd4-056d-4110-8db1-3518edd035bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10,\n",
              " 60,\n",
              " 28,\n",
              " 64,\n",
              " 46,\n",
              " 16,\n",
              " 26,\n",
              " 18,\n",
              " 93,\n",
              " 64,\n",
              " 12,\n",
              " 1,\n",
              " 46,\n",
              " 51,\n",
              " 52,\n",
              " 1,\n",
              " 64,\n",
              " 50,\n",
              " 5,\n",
              " 64,\n",
              " 26,\n",
              " 7,\n",
              " 46,\n",
              " 64,\n",
              " 94]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Organizando y estructurando el dataset"
      ],
      "metadata": {
        "id": "N8WVQ3vhbUrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ],
      "metadata": {
        "id": "foxYzdbFbY0o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ],
      "metadata": {
        "id": "imGkGH92bb4y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]\n",
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ],
      "metadata": {
        "id": "aJElgNmbbdoX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(tokenized_sentences_train[:-1])\n",
        "y_train = np.array(tokenized_sentences_train[1:])"
      ],
      "metadata": {
        "id": "uXTAOxNRbf6j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokenized_sentences_val))\n",
        "print(len(tokenized_sentences_val[0]))"
      ],
      "metadata": {
        "id": "icyWJhW4lNrn",
        "outputId": "4947f8ca-a25f-4f10-b5a3-eadc68985a48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "582\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como many-to-many:\n",
        "\n",
        "Entrada: secuencia de tokens $[x_0,x_1, ..., x_n]$\n",
        "\n",
        "Target: secuencia de tokens $[x_1,x_2, ...,x_{n+1}]$\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como many-to-one en donde sólo una señal de gradiente se propaga."
      ],
      "metadata": {
        "id": "Jh5er4kQcRxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este punto tenemos en la variable tokenized_sentences los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ],
      "metadata": {
        "id": "S6JOyq3Qcj1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjthpqMrcip3",
        "outputId": "c2d4c980-7a7d-436c-99c5-1527f526bb7a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(523265, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0,:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsan6E-vcnfC",
        "outputId": "3d619afd-74f1-4ae6-a7fe-d4d982e70cdd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10, 60, 28, 64, 46, 16, 26, 18, 93, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0,:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjsC_PzMcqo_",
        "outputId": "b1ad6b4e-0358-4dcc-cfda-f453cdd8028c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([60, 28, 64, 46, 16, 26, 18, 93, 64, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(chars_vocab)\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he78PmZcct-L",
        "outputId": "e5e18d61-4c32-4a34-cab4-b224f4c3995d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definiendo el modelo"
      ],
      "metadata": {
        "id": "6fSc4ocPcw7K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas CategoryEncoding que transforma a índices a vectores OHE y TimeDistributed que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia."
      ],
      "metadata": {
        "id": "-U8-Umk8c2aW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
        "from keras.models import Model, Sequential\n",
        "model = Sequential([\n",
        "    Input(shape=(None, 1)),\n",
        "    TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode=\"one_hot\")),\n",
        "    SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1),\n",
        "    Dense(vocab_size, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "T2gwQ1G9c13E",
        "outputId": "70b4213d-4f50-4fcb-9889-fb56ed72cf18"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)           │          \u001b[38;5;34m59,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │          \u001b[38;5;34m19,698\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">59,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,698</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,498\u001b[0m (310.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,498</span> (310.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,498\u001b[0m (310.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,498</span> (310.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perplexity callback"
      ],
      "metadata": {
        "id": "1qlDvuRzdL3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se tuvo que cambiar el enfoque de la implementación del cálculo de perplexity a un enfoque de tipo `batch` ya que la sesión de Colab se terminaba por quedarse sin memoria."
      ],
      "metadata": {
        "id": "BS8tVBL4CvB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import time\n",
        "class PplCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, val_data, history_ppl, patience=5, batch_size=512):\n",
        "        self.batch_size = batch_size\n",
        "        self.patience = patience\n",
        "        self.history_ppl = history_ppl\n",
        "\n",
        "        self.min_score = np.inf\n",
        "        self.patience_counter = 0\n",
        "\n",
        "        # Preprocess and flatten sequences and targets\n",
        "        self.sequences = []\n",
        "        self.targets = []\n",
        "        self.splits = []  # for perplexity aggregation later\n",
        "        idx = 0\n",
        "\n",
        "        for seq in val_data:\n",
        "            if len(seq) <= 1:\n",
        "                continue\n",
        "            subseq = [seq[:i] for i in range(1, len(seq))]\n",
        "            target = [seq[i] for i in range(1, len(seq))]\n",
        "\n",
        "            self.sequences.extend(subseq)\n",
        "            self.targets.extend(target)\n",
        "            self.splits.append((idx, idx + len(subseq)))\n",
        "            idx += len(subseq)\n",
        "\n",
        "        self.targets = np.array(self.targets)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        start_time = time.time()\n",
        "        print(\"\\nEvaluating perplexity on validation set...\")\n",
        "        preds_all = []\n",
        "\n",
        "        for i in range(0, len(self.sequences), self.batch_size):\n",
        "            batch_seqs = self.sequences[i:i+self.batch_size]\n",
        "            padded = pad_sequences(batch_seqs, maxlen=max_context_size, padding='pre')\n",
        "            preds = self.model.predict(padded, verbose=0)[:, -1, :]  # last step only\n",
        "            preds_all.append(preds)\n",
        "\n",
        "        predictions = np.vstack(preds_all)  # shape (N, vocab_size)\n",
        "\n",
        "        # Efficient probability lookup\n",
        "        chosen_probs = predictions[np.arange(len(predictions)), self.targets]\n",
        "        log_probs = np.log(chosen_probs + 1e-10)  # avoid log(0)\n",
        "\n",
        "        # Compute mean perplexity per sequence group\n",
        "        scores = []\n",
        "        for start, end in self.splits:\n",
        "            mean_log_prob = np.mean(log_probs[start:end])\n",
        "            scores.append(np.exp(-mean_log_prob))\n",
        "\n",
        "        current_score = np.mean(scores)\n",
        "        self.history_ppl.append(current_score)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f'\\nMean Perplexity: {current_score:.4f} | Evaluation Time: {elapsed:.2f} seconds\\n')\n",
        "\n",
        "\n",
        "        # Early stopping logic\n",
        "        if current_score < self.min_score:\n",
        "            self.min_score = current_score\n",
        "            self.model.save(\"my_model.keras\")\n",
        "            print(\"Saved new best model.\")\n",
        "            self.patience_counter = 0\n",
        "        else:\n",
        "            self.patience_counter += 1\n",
        "            if self.patience_counter >= self.patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                self.model.stop_training = True\n"
      ],
      "metadata": {
        "id": "LPZzuUBFkz0_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento"
      ],
      "metadata": {
        "id": "V8p5ErXYdWVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "# batch_size = 512 -> 61 segs perplex calc time\n",
        "# batch_size = 1024 -> 50 segs perplex calc time\n",
        "# batch_size = 2048 -> 43 segs perplex calc time <-- nos quedamos con este porque usa menos memoria y el beneficio en tiempo es aprox la misma que 4096\n",
        "# batch_size = 4096 -> 41.44 segs perplex calc time\n",
        "ppl_cb = PplCallback(val_data=tokenized_sentences_val, history_ppl=history_ppl, batch_size=2048)\n",
        "model.fit(X_train, y_train, epochs=20, callbacks=[ppl_cb], batch_size=1024)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "VbUBcxs6V9fV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Epoch 1/20\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - loss: 2.2485\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 10.9563 | Evaluation Time: 36.94 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 61s 115ms/step - loss: 2.2484\n",
        "Epoch 2/20\n",
        "510/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 2.0832\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 9.7245 | Evaluation Time: 35.89 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 76s 108ms/step - loss: 2.0830\n",
        "Epoch 3/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.9803\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 9.1274 | Evaluation Time: 35.50 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 55s 107ms/step - loss: 1.9803\n",
        "Epoch 4/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.9175\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.9740 | Evaluation Time: 37.15 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 84s 111ms/step - loss: 1.9174\n",
        "Epoch 5/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.8755\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.7260 | Evaluation Time: 36.53 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 56s 110ms/step - loss: 1.8754\n",
        "Epoch 6/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - loss: 1.8465\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.4781 | Evaluation Time: 37.64 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 83s 112ms/step - loss: 1.8465\n",
        "Epoch 7/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - loss: 1.8236\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.4720 | Evaluation Time: 35.53 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 80s 108ms/step - loss: 1.8236\n",
        "Epoch 8/20\n",
        "510/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.8069\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.5718 | Evaluation Time: 36.44 seconds\n",
        "\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 83s 110ms/step - loss: 1.8069\n",
        "Epoch 9/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7931\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.1454 | Evaluation Time: 35.76 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 55s 108ms/step - loss: 1.7931\n",
        "Epoch 10/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7810\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.2308 | Evaluation Time: 39.07 seconds\n",
        "\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 59s 115ms/step - loss: 1.7810\n",
        "Epoch 11/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7707\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.3993 | Evaluation Time: 36.41 seconds\n",
        "\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 79s 110ms/step - loss: 1.7707\n",
        "Epoch 12/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7633\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 7.4498 | Evaluation Time: 38.13 seconds\n",
        "\n",
        "Saved new best model.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 84s 113ms/step - loss: 1.7633\n",
        "Epoch 13/20\n",
        "510/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7554\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.3274 | Evaluation Time: 36.81 seconds\n",
        "\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 81s 110ms/step - loss: 1.7554\n",
        "Epoch 14/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7504\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.4714 | Evaluation Time: 38.36 seconds\n",
        "\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 83s 113ms/step - loss: 1.7504\n",
        "Epoch 15/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7443\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 8.5419 | Evaluation Time: 37.85 seconds\n",
        "\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 81s 112ms/step - loss: 1.7443\n",
        "Epoch 16/20\n",
        "510/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7386\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 7.9335 | Evaluation Time: 38.13 seconds\n",
        "\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 82s 113ms/step - loss: 1.7386\n",
        "Epoch 17/20\n",
        "511/512 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - loss: 1.7351\n",
        "Evaluating perplexity on validation set...\n",
        "\n",
        "Mean Perplexity: 7.7394 | Evaluation Time: 35.64 seconds\n",
        "\n",
        "Early stopping triggered.\n",
        "512/512 ━━━━━━━━━━━━━━━━━━━━ 79s 108ms/step - loss: 1.7351\n",
        "<keras.src.callbacks.history.History at 0x7c1d405cded0>\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "f5AKTOF7WPm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Zx7LpKR_WXID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "WCiudkIjWl03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model = keras.models.load_model('my_model.keras')"
      ],
      "metadata": {
        "id": "p3XMbs6kz-vF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicción del próximo caracter"
      ],
      "metadata": {
        "id": "w0eCJTcO0Cii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q gradio\n",
        "# import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "# iface = gr.Interface(\n",
        "#     fn=model_response,\n",
        "#     inputs=[\"textbox\"],\n",
        "#     outputs=\"text\")\n",
        "\n",
        "# iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "gOV5N1Wa0IiQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_response('Sherloc')"
      ],
      "metadata": {
        "id": "YzIWLtim1vYH",
        "outputId": "d42bb6e2-3689-4016-deac-5ee25625a48a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sherlock'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_response('Holme')"
      ],
      "metadata": {
        "id": "3fGjoZqN1y_N",
        "outputId": "fdab4940-1561-4b4b-a3ce-78cb70502348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Holmes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_response('Dr. Watso')"
      ],
      "metadata": {
        "id": "CviF4FYQ106B",
        "outputId": "fcc50ef7-aa87-4812-b1db-4030de0d59ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dr. Watson'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq = \"Sherlo\"\n",
        "for i in range(10):\n",
        "  seq = model_response(seq)\n",
        "  print(seq)"
      ],
      "metadata": {
        "id": "AhwdkiCB2pQq",
        "outputId": "e39832d5-2f1b-4ce5-c7b7-056648443cfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "Sherloc\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
            "Sherlock\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
            "Sherlock \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
            "Sherlock H\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Sherlock Ha\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Sherlock Had\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Sherlock Had \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Sherlock Had b\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Sherlock Had be\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Sherlock Had bee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq = \"Dr. Wats\"\n",
        "for i in range(10):\n",
        "  seq = model_response(seq)\n",
        "  print(seq)"
      ],
      "metadata": {
        "id": "rjbpcKcS2QeA",
        "outputId": "41f48425-bee2-42d7-80b9-e03a3438024d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "Dr. Watso\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "Dr. Watson\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
            "Dr. Watson,\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Dr. Watson, \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Dr. Watson, a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Dr. Watson, an\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Dr. Watson, and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Dr. Watson, and \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Dr. Watson, and a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Dr. Watson, and a \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación de secuencias"
      ],
      "metadata": {
        "id": "jDw6fhJp2_RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text\n"
      ],
      "metadata": {
        "id": "x0vurrET3Bot"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text='Sherlock'\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ],
      "metadata": {
        "id": "XkdEqj4x3FGu",
        "outputId": "95fd805f-5a72-4bbb-ef92-823517ebe553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sherlock Had been and a looked and a l'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text='Dr. Wats'\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ],
      "metadata": {
        "id": "Cke3ib0L3ZmP",
        "outputId": "2be3083e-f5ff-4c98-919f-ce539b9e8641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dr. Watson, and a looked and a looked '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beam search y muestreo aleatorio"
      ],
      "metadata": {
        "id": "nMZ5yX97QsCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ],
      "metadata": {
        "id": "PeOyq1gRQrN7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ],
      "metadata": {
        "id": "1aSDN5XKQuaA"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=20,input=\"Sherlock Holmes\")"
      ],
      "metadata": {
        "id": "TyqDgbwNQxh2"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "salidas[0]\n",
        ""
      ],
      "metadata": {
        "id": "G5CcLhGNQ4lp",
        "outputId": "22e985f7-c07e-4e63-ad77-3b00b7ba353c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([60, 25, 10, 80, 47, 79, 72, 81, 84, 18, 79, 47, 26, 10, 96, 24, 84,\n",
              "       56, 66, 34, 84, 40, 84, 96, 25, 79, 68, 47, 34, 84, 66, 79, 12, 84,\n",
              "       56])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[0])"
      ],
      "metadata": {
        "id": "yZpvdfdXQ6kn",
        "outputId": "82363cb7-1c99-4aa8-c66e-03410c415643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sherlock Holmes, and I should not a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analizamos el caso de utilizar una LSTM o GRU"
      ],
      "metadata": {
        "id": "wWbGkCVgRn7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM, GRU\n",
        "\n",
        "all_models = {}\n",
        "for model in [SimpleRNN, LSTM, GRU]:\n",
        "    complete_model = Sequential([\n",
        "        Input(shape=(None, 1)),\n",
        "        TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode=\"one_hot\")),\n",
        "        model(units=200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1),\n",
        "        Dense(vocab_size, activation=\"softmax\")\n",
        "    ])\n",
        "    complete_model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "    all_models[model.__name__] = complete_model\n",
        "    print(complete_model.summary())"
      ],
      "metadata": {
        "id": "_7zfaX89Rq22",
        "outputId": "f6a72eb0-ac2c-4932-8c42-2a87e718cb5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_1 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)           │          \u001b[38;5;34m59,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │          \u001b[38;5;34m19,698\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">59,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,698</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,498\u001b[0m (310.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,498</span> (310.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,498\u001b[0m (310.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,498</span> (310.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_2 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)           │         \u001b[38;5;34m239,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │          \u001b[38;5;34m19,698\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">239,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,698</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m258,898\u001b[0m (1011.32 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">258,898</span> (1011.32 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m258,898\u001b[0m (1011.32 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">258,898</span> (1011.32 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_3 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)           │         \u001b[38;5;34m180,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │          \u001b[38;5;34m19,698\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">180,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,698</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m199,698\u001b[0m (780.07 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">199,698</span> (780.07 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m199,698\u001b[0m (780.07 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">199,698</span> (780.07 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_perplexities = {}\n",
        "for name, curr_model in all_models.items():\n",
        "    print(f\"Using model with {name}\")\n",
        "    history_ppl = []\n",
        "    ppl_cb = PplCallback(val_data=tokenized_sentences_val, history_ppl=history_ppl, batch_size=2048)\n",
        "    curr_model.fit(X_train, y_train, epochs=20, callbacks=[ppl_cb], batch_size=1024)\n",
        "    all_perplexities[model.__name__] = history_ppl"
      ],
      "metadata": {
        "id": "D2KKR2aDRvzy",
        "outputId": "a763f54b-935a-44f9-fc53-29c654368eb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using model with SimpleRNN\n",
            "Epoch 1/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.8341\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 13.8481 | Evaluation Time: 48.59 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 136ms/step - loss: 2.8335\n",
            "Epoch 2/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.2027\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 10.3415 | Evaluation Time: 40.90 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 117ms/step - loss: 2.2025\n",
            "Epoch 3/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.0534\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 9.2882 | Evaluation Time: 41.42 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 119ms/step - loss: 2.0533\n",
            "Epoch 4/20\n",
            "\u001b[1m510/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.9640\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.7801 | Evaluation Time: 39.67 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 115ms/step - loss: 1.9639\n",
            "Epoch 5/20\n",
            "\u001b[1m510/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.9079\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.4488 | Evaluation Time: 40.96 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 117ms/step - loss: 1.9079\n",
            "Epoch 6/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.8693\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.1973 | Evaluation Time: 43.62 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 124ms/step - loss: 1.8693\n",
            "Epoch 7/20\n",
            "\u001b[1m510/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.8405\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.0061 | Evaluation Time: 39.80 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 117ms/step - loss: 1.8405\n",
            "Epoch 8/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.8186\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.8275 | Evaluation Time: 41.42 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 120ms/step - loss: 1.8186\n",
            "Epoch 9/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.8042\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.7598 | Evaluation Time: 42.13 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 121ms/step - loss: 1.8041\n",
            "Epoch 10/20\n",
            "\u001b[1m510/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.7913\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.6588 | Evaluation Time: 39.61 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 116ms/step - loss: 1.7913\n",
            "Epoch 11/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7783\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.9182 | Evaluation Time: 41.96 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 121ms/step - loss: 1.7783\n",
            "Epoch 12/20\n",
            "\u001b[1m510/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7695\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.7435 | Evaluation Time: 39.96 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 116ms/step - loss: 1.7695\n",
            "Epoch 13/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.7615\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.5068 | Evaluation Time: 42.23 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 120ms/step - loss: 1.7615\n",
            "Epoch 14/20\n",
            "\u001b[1m510/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7546\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.5171 | Evaluation Time: 42.00 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 120ms/step - loss: 1.7546\n",
            "Epoch 15/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7486\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.3975 | Evaluation Time: 39.93 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 117ms/step - loss: 1.7486\n",
            "Epoch 16/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7436\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.7584 | Evaluation Time: 43.57 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 124ms/step - loss: 1.7436\n",
            "Epoch 17/20\n",
            "\u001b[1m510/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.7386\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.8635 | Evaluation Time: 42.51 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 122ms/step - loss: 1.7386\n",
            "Epoch 18/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.7347\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.6922 | Evaluation Time: 42.76 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 122ms/step - loss: 1.7347\n",
            "Epoch 19/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7307\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.6172 | Evaluation Time: 41.38 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 119ms/step - loss: 1.7307\n",
            "Epoch 20/20\n",
            "\u001b[1m510/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7277\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.4588 | Evaluation Time: 41.75 seconds\n",
            "\n",
            "Early stopping triggered.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 120ms/step - loss: 1.7277\n",
            "Using model with LSTM\n",
            "Epoch 1/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 3.0995\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 17.5020 | Evaluation Time: 363.53 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 994ms/step - loss: 3.0990\n",
            "Epoch 2/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - loss: 2.4555\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 17.1222 | Evaluation Time: 354.95 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 976ms/step - loss: 2.4554\n",
            "Epoch 3/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 2.3030\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 13.7097 | Evaluation Time: 368.24 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 1s/step - loss: 2.3030 \n",
            "Epoch 4/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - loss: 2.2108\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 12.1158 | Evaluation Time: 365.95 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 998ms/step - loss: 2.2108\n",
            "Epoch 5/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - loss: 2.1425\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 11.6747 | Evaluation Time: 369.66 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 1s/step - loss: 2.1425 \n",
            "Epoch 6/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 2.0867\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 10.7270 | Evaluation Time: 359.49 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 981ms/step - loss: 2.0867\n",
            "Epoch 7/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - loss: 2.0418\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 10.7718 | Evaluation Time: 353.74 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m496s\u001b[0m 971ms/step - loss: 2.0417\n",
            "Epoch 8/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 2.0040\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 10.1535 | Evaluation Time: 350.25 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 964ms/step - loss: 2.0040\n",
            "Epoch 9/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 1.9700\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 9.5704 | Evaluation Time: 368.84 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 999ms/step - loss: 1.9700\n",
            "Epoch 10/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 1.9407\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 9.1829 | Evaluation Time: 368.73 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m511s\u001b[0m 1000ms/step - loss: 1.9407\n",
            "Epoch 11/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - loss: 1.9135\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 9.1763 | Evaluation Time: 369.13 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 1s/step - loss: 1.9135 \n",
            "Epoch 12/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 1.8887\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.8088 | Evaluation Time: 358.72 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 979ms/step - loss: 1.8887\n",
            "Epoch 13/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 1.8661\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.8651 | Evaluation Time: 377.26 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 1s/step - loss: 1.8661 \n",
            "Epoch 14/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 1.8466\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.5137 | Evaluation Time: 350.20 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 964ms/step - loss: 1.8466\n",
            "Epoch 15/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - loss: 1.8283\n",
            "Evaluating perplexity on validation set...\n"
          ]
        }
      ]
    }
  ]
}