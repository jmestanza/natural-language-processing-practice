{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmestanza/natural-language-processing-practice/blob/main/desafios/Desafio_3/Desafio_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desafío 3\n",
        "Entrenar un modelo de lenguaje basado en caracteres utilizando la [notebook](https://github.com/jmestanza/procesamiento_lenguaje_natural/blob/main/clase_3/ejercicios/3_modelo_lenguaje_char.ipynb) de clase como base .\n",
        "\n",
        "Objetivos principales\n",
        "- Comprender el modelo de lenguaje basado en caracteres.\n",
        "- Definir un corpus para entrenar el modelo.\n",
        "- Tomar decisiones sobre la arquitectura del modelo.\n",
        "- Ejecutar el entrenamiento y analizar los resultados.\n",
        "- Generar secuencias de texto utilizando el modelo entrenado.\n",
        "\n",
        "\n",
        "Se define un vocabulario de caracteres, incluyendo letras, signos de puntuación y espacios.\n",
        "\n",
        "Se crean diccionarios de tokenización (carácter a índice y viceversa).\n",
        "\n",
        "El modelo se entrena en un esquema many-to-many, donde la entrada es una secuencia de caracteres y la salida es la misma secuencia desplazada en un carácter.\n",
        "\n",
        "Se menciona el uso de capa embedding y time-distributed layers para manejar secuencias.\n",
        "\n",
        "Generación de texto\n",
        "Se propone experimentar con diferentes estrategias de generación de secuencias.\n",
        "\n",
        "Se pueden probar enfoques deterministas o estocásticos para generar texto.\n",
        "\n",
        "Se debe documentar los resultados de generación obtenidos con el modelo final.\n",
        "\n",
        "Entrega esperada\n",
        "Modelo de lenguaje entrenado con la arquitectura seleccionada.\n",
        "\n",
        "Ejemplos de generación de texto con el modelo.\n",
        "\n",
        "Reflexión sobre los resultados y ajustes realizados.\n",
        "\n",
        "En resumen, el trabajo implica entrenar un modelo de lenguaje basado en caracteres, ajustar su arquitectura, medir su rendimiento y generar texto con él."
      ],
      "metadata": {
        "id": "JGWTDDTSXMWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "Originalmente, se había optado por el dataset `THE COMPLETE SHERLOCK HOLMES` que tiene todo el canon de los libros de Arthur Conan Doyle. Pero debido a que es un corpus muy grande  (3868122 de caracteres), la sesión se queda sin ram. Por lo cual se optó por un corpus más chico `The Adventures of Sherlock Holmes` (581565 caracteres)."
      ],
      "metadata": {
        "id": "qnJwd89JZ32_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "dataset_path = 'the_adventures_of_sherlock_holmes.txt'\n",
        "if not os.path.exists(dataset_path):\n",
        "  # !wget https://raw.githubusercontent.com/jmestanza/natural-language-processing-practice/refs/heads/main/desafios/Desafio_2/cano.txt\n",
        "  !wget https://raw.githubusercontent.com/jmestanza/natural-language-processing-practice/refs/heads/main/desafios/Desafio_2/the_adventures_of_sherlock_holmes.txt"
      ],
      "metadata": {
        "id": "2s4QTbQwXP-m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(dataset_path, 'r') as f:\n",
        "  text = f.read()\n",
        "\n",
        "print(len(text))\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKvsSbtjak1-",
        "outputId": "3dd12190-3b77-4d63-b7e2-a0b6435b6b4f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "581565\n",
            "﻿The Project Gutenberg eBook of The Adventures of Sherlock Holmes\n",
            "    \n",
            "This ebook is for the use of anyone anywhere in the United States and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\n",
            "of the Project Gutenberg License included with this ebook or online\n",
            "at www.gutenberg.org. If you are not located in the United States,\n",
            "you will have to check the laws of the country where you are located\n",
            "before using this eBook.\n",
            "\n",
            "Title: The Adventures of Sherlock Holmes\n",
            "\n",
            "Author: Arthur Conan Doyle\n",
            "\n",
            "Release date: March 1, 1999 [eBook #1661]\n",
            "                Most recently updated: October 10, 2023\n",
            "\n",
            "Language: English\n",
            "\n",
            "Credits: an anonymous Project Gutenberg volunteer and Jose Menendez\n",
            "\n",
            "\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK THE ADVENTURES OF SHERLOCK HOLMES ***\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The Adventures of Sherlock Holmes\n",
            "\n",
            "by Arthur Conan Doyle\n",
            "\n",
            "\n",
            "Contents\n",
            "\n",
            "   I.     A Scandal in Bohemia\n",
            "   II.    The Red-Headed League\n",
            "   III.   A \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus de texto puede ser considerado un documento en sí mismo y el tamaño de contexto puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ],
      "metadata": {
        "id": "uj17kqEPat1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100\n",
        "\n",
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding\n",
        "\n",
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(text)\n",
        "\n",
        "# la longitud de vocabulario de caracteres es:\n",
        "print(len(chars_vocab))\n",
        "\n",
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}\n"
      ],
      "metadata": {
        "id": "2TFAHyg9ar9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e1bdf47-b118-406c-bc43-21915eecfa7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizar"
      ],
      "metadata": {
        "id": "oalbHoONbH2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in text]\n",
        "tokenized_text[:25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnzWy8DRbHZ_",
        "outputId": "bc18be94-539b-4583-88eb-de884fa9e354"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[33,\n",
              " 85,\n",
              " 25,\n",
              " 10,\n",
              " 84,\n",
              " 77,\n",
              " 80,\n",
              " 79,\n",
              " 19,\n",
              " 10,\n",
              " 72,\n",
              " 12,\n",
              " 84,\n",
              " 0,\n",
              " 68,\n",
              " 12,\n",
              " 10,\n",
              " 66,\n",
              " 22,\n",
              " 10,\n",
              " 80,\n",
              " 27,\n",
              " 84,\n",
              " 10,\n",
              " 89]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Organizando y estructurando el dataset"
      ],
      "metadata": {
        "id": "N8WVQ3vhbUrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ],
      "metadata": {
        "id": "foxYzdbFbY0o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ],
      "metadata": {
        "id": "imGkGH92bb4y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]\n",
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ],
      "metadata": {
        "id": "aJElgNmbbdoX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(tokenized_sentences_train[:-1])\n",
        "y_train = np.array(tokenized_sentences_train[1:])"
      ],
      "metadata": {
        "id": "uXTAOxNRbf6j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokenized_sentences_val))\n",
        "print(len(tokenized_sentences_val[0]))"
      ],
      "metadata": {
        "id": "icyWJhW4lNrn",
        "outputId": "0d627311-ac9c-4ada-908d-5991f5dc9a73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "582\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como many-to-many:\n",
        "\n",
        "Entrada: secuencia de tokens $[x_0,x_1, ..., x_n]$\n",
        "\n",
        "Target: secuencia de tokens $[x_1,x_2, ...,x_{n+1}]$\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como many-to-one en donde sólo una señal de gradiente se propaga."
      ],
      "metadata": {
        "id": "Jh5er4kQcRxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este punto tenemos en la variable tokenized_sentences los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ],
      "metadata": {
        "id": "S6JOyq3Qcj1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjthpqMrcip3",
        "outputId": "dff77df4-a715-4099-b153-02fa6811c16b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(523265, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0,:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsan6E-vcnfC",
        "outputId": "7d23a812-4f8c-4b32-ef90-b0d0d49972e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([33, 85, 25, 10, 84, 77, 80, 79, 19, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0,:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjsC_PzMcqo_",
        "outputId": "672c7363-2edc-443d-f94e-aad7dbd2a41c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([85, 25, 10, 84, 77, 80, 79, 19, 10, 72])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(chars_vocab)\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he78PmZcct-L",
        "outputId": "efc539bf-2f62-4f15-8a47-6b28262160d3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definiendo el modelo"
      ],
      "metadata": {
        "id": "6fSc4ocPcw7K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas CategoryEncoding que transforma a índices a vectores OHE y TimeDistributed que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia."
      ],
      "metadata": {
        "id": "-U8-Umk8c2aW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
        "from keras.models import Model, Sequential\n",
        "model = Sequential([\n",
        "    Input(shape=(None, 1)),\n",
        "    TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode=\"one_hot\")),\n",
        "    SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1),\n",
        "    Dense(vocab_size, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "T2gwQ1G9c13E",
        "outputId": "19284d4a-6232-46c7-bbeb-778fecc021c5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_1 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)           │          \u001b[38;5;34m59,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │          \u001b[38;5;34m19,698\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">59,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,698</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,498\u001b[0m (310.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,498</span> (310.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,498\u001b[0m (310.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,498</span> (310.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perplexity callback"
      ],
      "metadata": {
        "id": "1qlDvuRzdL3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se tuvo que cambiar el enfoque de la implementación del cálculo de perplexity a un enfoque de tipo `batch` ya que la sesión de Colab se terminaba por quedarse sin memoria."
      ],
      "metadata": {
        "id": "BS8tVBL4CvB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import time\n",
        "class PplCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, val_data, history_ppl, patience=5, batch_size=512):\n",
        "        self.batch_size = batch_size\n",
        "        self.patience = patience\n",
        "        self.history_ppl = history_ppl\n",
        "\n",
        "        self.min_score = np.inf\n",
        "        self.patience_counter = 0\n",
        "\n",
        "        # Preprocess and flatten sequences and targets\n",
        "        self.sequences = []\n",
        "        self.targets = []\n",
        "        self.splits = []  # for perplexity aggregation later\n",
        "        idx = 0\n",
        "\n",
        "        for seq in val_data:\n",
        "            if len(seq) <= 1:\n",
        "                continue\n",
        "            subseq = [seq[:i] for i in range(1, len(seq))]\n",
        "            target = [seq[i] for i in range(1, len(seq))]\n",
        "\n",
        "            self.sequences.extend(subseq)\n",
        "            self.targets.extend(target)\n",
        "            self.splits.append((idx, idx + len(subseq)))\n",
        "            idx += len(subseq)\n",
        "\n",
        "        self.targets = np.array(self.targets)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        start_time = time.time()\n",
        "        print(\"\\nEvaluating perplexity on validation set...\")\n",
        "        preds_all = []\n",
        "\n",
        "        for i in range(0, len(self.sequences), self.batch_size):\n",
        "            batch_seqs = self.sequences[i:i+self.batch_size]\n",
        "            padded = pad_sequences(batch_seqs, maxlen=max_context_size, padding='pre')\n",
        "            preds = self.model.predict(padded, verbose=0)[:, -1, :]  # last step only\n",
        "            preds_all.append(preds)\n",
        "\n",
        "        predictions = np.vstack(preds_all)  # shape (N, vocab_size)\n",
        "\n",
        "        # Efficient probability lookup\n",
        "        chosen_probs = predictions[np.arange(len(predictions)), self.targets]\n",
        "        log_probs = np.log(chosen_probs + 1e-10)  # avoid log(0)\n",
        "\n",
        "        # Compute mean perplexity per sequence group\n",
        "        scores = []\n",
        "        for start, end in self.splits:\n",
        "            mean_log_prob = np.mean(log_probs[start:end])\n",
        "            scores.append(np.exp(-mean_log_prob))\n",
        "\n",
        "        current_score = np.mean(scores)\n",
        "        self.history_ppl.append(current_score)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f'\\nMean Perplexity: {current_score:.4f} | Evaluation Time: {elapsed:.2f} seconds\\n')\n",
        "\n",
        "\n",
        "        # Early stopping logic\n",
        "        if current_score < self.min_score:\n",
        "            self.min_score = current_score\n",
        "            self.model.save(\"my_model.keras\")\n",
        "            print(\"Saved new best model.\")\n",
        "            self.patience_counter = 0\n",
        "        else:\n",
        "            self.patience_counter += 1\n",
        "            if self.patience_counter >= self.patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                self.model.stop_training = True\n"
      ],
      "metadata": {
        "id": "LPZzuUBFkz0_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento"
      ],
      "metadata": {
        "id": "V8p5ErXYdWVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "# batch_size = 512 -> 61 segs perplex calc time\n",
        "# batch_size = 1024 -> 50 segs perplex calc time\n",
        "# batch_size = 2048 -> 43 segs perplex calc time <-- nos quedamos con este porque usa menos memoria y el beneficio en tiempo es aprox la misma que 4096\n",
        "# batch_size = 4096 -> 41.44 segs perplex calc time\n",
        "ppl_cb = PplCallback(val_data=tokenized_sentences_val, history_ppl=history_ppl, batch_size=2048)\n",
        "model.fit(X_train, y_train, epochs=20, callbacks=[ppl_cb], batch_size=1024)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOqag3epdZ4k",
        "outputId": "c3b3d195-2679-4f4d-a4ad-ecfabb9282b2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 2.2485\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 10.9563 | Evaluation Time: 36.94 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 115ms/step - loss: 2.2484\n",
            "Epoch 2/20\n",
            "\u001b[1m510/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.0832\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 9.7245 | Evaluation Time: 35.89 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 108ms/step - loss: 2.0830\n",
            "Epoch 3/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.9803\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 9.1274 | Evaluation Time: 35.50 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 107ms/step - loss: 1.9803\n",
            "Epoch 4/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.9175\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.9740 | Evaluation Time: 37.15 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 111ms/step - loss: 1.9174\n",
            "Epoch 5/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.8755\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.7260 | Evaluation Time: 36.53 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 110ms/step - loss: 1.8754\n",
            "Epoch 6/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.8465\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.4781 | Evaluation Time: 37.64 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 112ms/step - loss: 1.8465\n",
            "Epoch 7/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.8236\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.4720 | Evaluation Time: 35.53 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 108ms/step - loss: 1.8236\n",
            "Epoch 8/20\n",
            "\u001b[1m510/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.8069\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.5718 | Evaluation Time: 36.44 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 110ms/step - loss: 1.8069\n",
            "Epoch 9/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7931\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.1454 | Evaluation Time: 35.76 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 108ms/step - loss: 1.7931\n",
            "Epoch 10/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7810\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.2308 | Evaluation Time: 39.07 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 115ms/step - loss: 1.7810\n",
            "Epoch 11/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7707\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.3993 | Evaluation Time: 36.41 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 110ms/step - loss: 1.7707\n",
            "Epoch 12/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7633\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.4498 | Evaluation Time: 38.13 seconds\n",
            "\n",
            "Saved new best model.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 113ms/step - loss: 1.7633\n",
            "Epoch 13/20\n",
            "\u001b[1m510/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7554\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.3274 | Evaluation Time: 36.81 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 110ms/step - loss: 1.7554\n",
            "Epoch 14/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7504\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.4714 | Evaluation Time: 38.36 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 113ms/step - loss: 1.7504\n",
            "Epoch 15/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7443\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 8.5419 | Evaluation Time: 37.85 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 112ms/step - loss: 1.7443\n",
            "Epoch 16/20\n",
            "\u001b[1m510/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7386\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.9335 | Evaluation Time: 38.13 seconds\n",
            "\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 113ms/step - loss: 1.7386\n",
            "Epoch 17/20\n",
            "\u001b[1m511/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7351\n",
            "Evaluating perplexity on validation set...\n",
            "\n",
            "Mean Perplexity: 7.7394 | Evaluation Time: 35.64 seconds\n",
            "\n",
            "Early stopping triggered.\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 108ms/step - loss: 1.7351\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c1d405cded0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7Y4thBF7z8bP",
        "outputId": "c11f101a-29ad-4b65-f4b8-a1fde2b3d8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model = keras.models.load_model('my_model.keras')"
      ],
      "metadata": {
        "id": "p3XMbs6kz-vF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicción del próximo caracter"
      ],
      "metadata": {
        "id": "w0eCJTcO0Cii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q gradio\n",
        "# import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "# iface = gr.Interface(\n",
        "#     fn=model_response,\n",
        "#     inputs=[\"textbox\"],\n",
        "#     outputs=\"text\")\n",
        "\n",
        "# iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "gOV5N1Wa0IiQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_response('Sherloc')"
      ],
      "metadata": {
        "id": "YzIWLtim1vYH",
        "outputId": "d42bb6e2-3689-4016-deac-5ee25625a48a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sherlock'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_response('Holme')"
      ],
      "metadata": {
        "id": "3fGjoZqN1y_N",
        "outputId": "fdab4940-1561-4b4b-a3ce-78cb70502348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Holmes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_response('Dr. Watso')"
      ],
      "metadata": {
        "id": "CviF4FYQ106B",
        "outputId": "fcc50ef7-aa87-4812-b1db-4030de0d59ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dr. Watson'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq = \"Sherlo\"\n",
        "for i in range(10):\n",
        "  seq = model_response(seq)\n",
        "  print(seq)"
      ],
      "metadata": {
        "id": "AhwdkiCB2pQq",
        "outputId": "e39832d5-2f1b-4ce5-c7b7-056648443cfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "Sherloc\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
            "Sherlock\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
            "Sherlock \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
            "Sherlock H\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Sherlock Ha\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Sherlock Had\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Sherlock Had \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Sherlock Had b\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Sherlock Had be\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Sherlock Had bee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq = \"Dr. Wats\"\n",
        "for i in range(10):\n",
        "  seq = model_response(seq)\n",
        "  print(seq)"
      ],
      "metadata": {
        "id": "rjbpcKcS2QeA",
        "outputId": "41f48425-bee2-42d7-80b9-e03a3438024d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "Dr. Watso\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "Dr. Watson\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
            "Dr. Watson,\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Dr. Watson, \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Dr. Watson, a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Dr. Watson, an\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Dr. Watson, and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Dr. Watson, and \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Dr. Watson, and a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Dr. Watson, and a \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación de secuencias"
      ],
      "metadata": {
        "id": "jDw6fhJp2_RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text\n"
      ],
      "metadata": {
        "id": "x0vurrET3Bot"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text='Sherlock'\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ],
      "metadata": {
        "id": "XkdEqj4x3FGu",
        "outputId": "95fd805f-5a72-4bbb-ef92-823517ebe553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sherlock Had been and a looked and a l'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text='Dr. Wats'\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ],
      "metadata": {
        "id": "Cke3ib0L3ZmP",
        "outputId": "2be3083e-f5ff-4c98-919f-ce539b9e8641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dr. Watson, and a looked and a looked '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}